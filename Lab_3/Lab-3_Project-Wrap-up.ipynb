{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "765132cf",
   "metadata": {},
   "source": [
    "# Recap of Labs 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b53b8a",
   "metadata": {},
   "source": [
    "# Lab 1: Locating and Exploring Datasets\n",
    "\n",
    "Welcome to the first assignment of the course 'AI-powered Data Analysis'. In this assignment, you will learn how to locate and open datasets stored as CSV files, understand their structure, and explore their components.\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this assignment, we will explore the process of data analysis, starting from the very basics of locating and opening datasets saved as CSV files, understanding their structure, and exploring their components.\n",
    "\n",
    "### Importance of Metadata\n",
    "\n",
    "When given a dataset, the first step is to look at the metadata. Metadata provides crucial information about the data, such as:\n",
    "- The structure of the dataset (e.g., column names, data types)\n",
    "- Descriptions of the data fields\n",
    "- Information about the source and context of the data\n",
    "\n",
    "Understanding the metadata is beneficial because:\n",
    "- It helps in comprehending the dataset's structure and content.\n",
    "- It provides insights into the data quality and potential preprocessing steps needed.\n",
    "- It aids in planning the data analysis and visualization strategies effectively.\n",
    "\n",
    "### Datasets Overview\n",
    "\n",
    "We will be using three datasets in this assignment:\n",
    "\n",
    "1. **NOAA Weather Dataset**\n",
    "    - This dataset contains weather data collected by the National Oceanic and Atmospheric Administration (NOAA).\n",
    "    - [Link to Metadata](#)\n",
    "\n",
    "2. **Kaggle Ecommerce Dataset**\n",
    "    - This dataset comprises e-commerce data from Kaggle, including information about transactions, products, and customers.\n",
    "    - [Link to Metadata](#)\n",
    "\n",
    "3. **Yelp Reviews Dataset**\n",
    "    - This dataset includes reviews from Yelp, with columns such as 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Score', 'Time', 'Summary', and 'Text'.\n",
    "    - [Link to Metadata](#)\n",
    "\n",
    "After understanding the metadata and the structure of our datasets, we will proceed with coding to explore and analyze the data.\n",
    "\n",
    "\n",
    "### Datasets Information\n",
    "\n",
    "In this course, we have three different datasets housed within the following file directory structure:\n",
    "\n",
    "As you can see, a dataset may contain multiple CSV files. For this assignment, we will be using the `bank_churners.csv` file in the `Kaggle_Ecommerce` folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb6510",
   "metadata": {},
   "source": [
    "## Introduction to Dataset Overview and Metadata\n",
    "\n",
    "Before diving into data analysis, it is crucial to get an overview of the dataset and understand its metadata. This initial step provides valuable insights into the data's structure, quality, and the types of information it contains.\n",
    "\n",
    "### Why Summarize the Dataset Overview?\n",
    "\n",
    "- **Quick Insights:** A summary gives a quick glance at the main features of the dataset.\n",
    "- **Data Quality:** Helps in identifying any immediate data quality issues.\n",
    "- **Preparation for Analysis:** Prepares the ground for more detailed data analysis and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd50b02",
   "metadata": {},
   "source": [
    "## 1. Locating and Opening CSV Files\n",
    "\n",
    "First, let's locate and open the CSV files. We'll use the Kaggle Ecommerce Data for this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42159aab",
   "metadata": {},
   "source": [
    "### List all files in the `Kaggle Ecommerce` folder\n",
    "We will use the `os` module to list all files in the folder.\n",
    "\n",
    "1. **Import the `os` module**\n",
    "\n",
    "```python\n",
    "import os\n",
    "```\n",
    "\n",
    "The `os` module provides functions to interact with the operating system, such as listing files in a directory.\n",
    "\n",
    "2. **List all files in the `Kaggle Ecommerce` folder**\n",
    "\n",
    "```python\n",
    "files = os.listdir('../Datasets/Kaggle_Ecommerce')\n",
    "files\n",
    "```\n",
    "\n",
    "- `os.listdir('../Datasets/Kaggle_Ecommerce')` lists all files and directories in the `Kaggle_Ecommerce` folder.\n",
    "- The result is stored in the variable `files`.\n",
    "- `files` is then displayed to show the list of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44d6e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir('../Datasets/Kaggle_Ecommerce')\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418b610a",
   "metadata": {},
   "source": [
    "### Explanation of the above code cell\n",
    "The above code cell imports the `os` module and lists all files in the `Kaggle_Ecommerce` folder. The `os.listdir()` function retrieves the names of all files and directories in the specified folder. The result is stored in the variable `files`, which is then displayed. This helps in identifying the available CSV files for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99074f60",
   "metadata": {},
   "source": [
    "### Read and display the first few rows of a CSV file\n",
    "We will use the `pandas` library to read the CSV file and display its first few rows.\n",
    "\n",
    "1. **Import the `pandas` library**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "The `pandas` library is used for data manipulation and analysis.\n",
    "\n",
    "2. **Read the first CSV file**\n",
    "\n",
    "```python\n",
    "file_path = os.path.join('../Datasets/Kaggle_Ecommerce', files[0])\n",
    "```\n",
    "\n",
    "- `os.path.join('../Datasets/Kaggle_Ecommerce', files[0])` creates the full path to the first file in the `Kaggle_Ecommerce` folder.\n",
    "- The result is stored in the variable `file_path`.\n",
    "\n",
    "3. **Load the CSV file into a DataFrame**\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(file_path)\n",
    "```\n",
    "\n",
    "- `pd.read_csv(file_path)` reads the CSV file and loads its contents into a `pandas` DataFrame.\n",
    "- The DataFrame is stored in the variable `df`.\n",
    "\n",
    "4. **Display the first few rows of the DataFrame**\n",
    "\n",
    "```python\n",
    "df.head()\n",
    "```\n",
    "\n",
    "- `df.head()` displays the first five rows of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the bank_churners CSV file\n",
    "file_path = os.path.join('../Datasets/Kaggle_Ecommerce', files[0])\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c40d75b",
   "metadata": {},
   "source": [
    "The first five rows of the DataFrame are displayed using `df.head()`. This provides a quick overview of the data structure and the initial few records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecb8108-2d8c-461f-b5ef-2e72e56ffb42",
   "metadata": {},
   "source": [
    "\n",
    "### Get the number of rows in the DataFrame\n",
    "\n",
    "We will use the `len()` function to get the number of rows in the DataFrame.\n",
    "\n",
    "1. **Get the number of rows**\n",
    "\n",
    "```python\n",
    "num_rows = len(df)\n",
    "num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c38c7d-ea15-4b79-ac90-ccb8356d548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = len(df)\n",
    "num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145440f2",
   "metadata": {},
   "source": [
    "This number represents the total number of records in the dataset. This information is crucial for understanding the dataset's size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bffa51",
   "metadata": {},
   "source": [
    "## 2. Understanding the Structure\n",
    "\n",
    "Let's get more information about the dataset to understand its structure better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f4efc3-aeb1-4b3d-913c-bd16214f3280",
   "metadata": {},
   "source": [
    "### Get the column names in the DataFrame\n",
    "\n",
    "We will use the `.columns` attribute of the DataFrame to get the column names.\n",
    "\n",
    "1. **Get the column names**\n",
    "\n",
    "```python\n",
    "columns = df.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de6f5d5-84b2-4626-a3b5-5bd63bacffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ada931",
   "metadata": {},
   "source": [
    "The list of items inside the square brackets `[]` is the columns that the DataFrame has. This allows you to see all the column names at a glance. This can be especially helpful when dealing with large datasets or when you want to programmatically interact with the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e99dfe",
   "metadata": {},
   "source": [
    "### Get basic information about the dataframe\n",
    "We will use the `info()` method to get a concise summary of the dataframe, including the number of non-null values and data types of each column.\n",
    "\n",
    "1. **Get a concise summary of the DataFrame**\n",
    "\n",
    "```python\n",
    "df.info()\n",
    "```\n",
    "\n",
    "- `df.info()` displays a concise summary of the DataFrame.\n",
    "- It shows the number of non-null values, data types of each column, and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10abbf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8272257f-e275-4061-a08c-10afbd0f8a8e",
   "metadata": {},
   "source": [
    "**A detailed breakdown of the above output is:**\n",
    "\n",
    "\n",
    "**Class Type:**\n",
    "\n",
    "- The first line `<class 'pandas.core.frame.DataFrame'>` tells you that the object is a DataFrame.\n",
    "\n",
    "**Index Range:**\n",
    "\n",
    "- `RangeIndex: 10127 entries, 0 to 10126` indicates that the DataFrame has an Index with 10127 entries ranging from 0 to 10126.\n",
    "\n",
    "**Column Information:**\n",
    "\n",
    "- `Data columns (total 21 columns):` indicates that there are 21 columns in the DataFrame.\n",
    "\n",
    "**Column Details:**\n",
    "\n",
    "- For each column, you get the column number (starting from 0), the column name, the count of non-null values, and the data type\n",
    "- `non-null` means there are no null entries in the column\n",
    "\n",
    "**Data Types Summary**\n",
    "\n",
    "- `dtypes: float64(5), int64(10), object(6)` summarizes the data types present in the DataFrame and their counts, `object` in Pandas represents a string.\n",
    "\n",
    "**Memory** \n",
    "- `memory usage: ... MB` indicates the memory usage of the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e12f95c",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65190617-4cb0-46cf-be12-61fc8fb06d0e",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing and Cleaning\n",
    "\n",
    "Data preprocessing and cleaning are critical steps in the data analysis pipeline. The quality of data directly impacts the quality of insights that can be derived from it. Preprocessing involves transforming raw data into a clean and usable format. Cleaning involves handling missing values, correcting errors, and preparing the data for analysis.\n",
    "\n",
    "### Handling Missing Values\n",
    "Missing values are common in datasets and can significantly affect the results of your analysis. Common strategies to handle missing values include:\n",
    "- **Removal**: Removing rows or columns with missing values.\n",
    "- **Imputation**: Filling missing values with a specific value such as the mean, median, or mode of the column.\n",
    "- **Prediction**: Using machine learning models to predict missing values based on other features.\n",
    "\n",
    "Let's start by importing the required libraries and loading the CSV file for `shopping_behavior` dataset in `Kaggle Ecommerce` and examining the data to identify errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c14ae3-e570-4a9f-b845-af29fa37927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = '../Datasets/Kaggle_Ecommerce/shopping_behavior.csv'\n",
    "shop_behav = pd.read_csv(file_path)\n",
    "shop_behav.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e3fdb0-48ce-4999-9406-d3442ccd0b94",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "Identify and handle missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad4bfed",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bc2e7a-95ce-44bf-8d94-0cc751091287",
   "metadata": {},
   "source": [
    "This code checks for missing values in the `shop_behav` DataFrame.\n",
    "\n",
    "- **shop_behav.isnull()**: Identifies all the null (missing) values in the DataFrame.\n",
    "- **sum()**: Counts the total number of missing values in each column.\n",
    "\n",
    "The result shows the number of missing values per column, helping us understand the extent of missing data in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73273b0e-a2f1-463c-8023-53a16727ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify missing values\n",
    "shop_behav.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a12323b-86e4-489c-a551-322ce72c3764",
   "metadata": {},
   "source": [
    "This code handles missing values in the `shop_behav` DataFrame. Here, we are filling the missing values with the mean of the corresponding column.\n",
    "\n",
    "- **missing_cols**: Identifies columns with any missing values.\n",
    "- **for col in missing_cols**: Iterates through each column with missing values.\n",
    "    - **if shop_behav[col].dtype in [np.float64, np.int64]**: Checks if the column is numerical.\n",
    "    - **shop_behav[col].fillna(shop_behav[col].mean(), inplace=True)**: Fills missing values in numerical columns with the column mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd069d42",
   "metadata": {},
   "source": [
    "## Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db61676a-bf39-4df1-afb9-50245effb9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with missing values\n",
    "missing_cols = shop_behav.columns[shop_behav.isnull().any()]\n",
    "\n",
    "# Fill missing values in numerical columns with mean\n",
    "for col in missing_cols:\n",
    "    if shop_behav[col].dtype in [np.float64, np.int64]:\n",
    "        shop_behav[col].fillna(shop_behav[col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d997335f-cfc2-4020-b502-d048adc1550d",
   "metadata": {},
   "source": [
    "We again check for missing values, and as can be seen, there are none left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a3622c-640c-40e2-94d8-398fd2481b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rechecking for missing values\n",
    "shop_behav.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d381c2-ad94-44c9-9499-cdf098b1a024",
   "metadata": {},
   "source": [
    "### Removing Duplicates\n",
    "Duplicate records can skew your analysis and lead to incorrect insights. Removing duplicates ensures that each record in your dataset is unique. This is typically done by identifying and removing rows that have identical values across all columns.\n",
    "\n",
    "This code checks for duplicate rows in the `shov_behav` DataFrame.\n",
    "\n",
    "- **data2.duplicated()**: Identifies duplicate rows.\n",
    "- **sum()**: Counts the total number of duplicate rows in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e813005-dd64-4ea7-b404-95d4bd079227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify duplicates\n",
    "shop_behav.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd652bd-8d98-4ade-901b-6ea42ed4d657",
   "metadata": {},
   "source": [
    "This indicates that the dataset has one duplicate row. We will fix it now.\n",
    "\n",
    "- **shop_behav.drop_duplicates(inplace=True)**: Removes duplicate rows from the DataFrame and updates `shop_behav` in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7002d9-f5f9-479e-964d-4d2022673128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "shop_behav.drop_duplicates(inplace=True)\n",
    "shop_behav.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf72bc9-c2a7-4946-b37d-759eee326a3f",
   "metadata": {},
   "source": [
    "The dataset now has no duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae4ba5-fc3b-4eff-9662-a04ef3677e5a",
   "metadata": {},
   "source": [
    "### Data Type Conversion\n",
    "Ensuring that each column has the correct data type is crucial for accurate analysis because each column in a DataFrame can only contain one data type. This restriction comes from the underlying structure of a DataFrame, which is essentially a 2D array, where each column must be homogenous, unlike a list that can contain mixed types. For example, dates should be converted to datetime objects, numerical data should be in appropriate numerical formats, and categorical data should be stored as category types where applicable.\n",
    "\n",
    "Let's consider the example of the 'Review Rating' column. This column should be of float type, but due to some rows (as shown below), the datatype is currently an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b6b1a1-b2ab-4b68-b16b-71766b587e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_behav['Review Rating'][55:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67babe23-6214-4a54-8b16-bf054d101e8b",
   "metadata": {},
   "source": [
    "1. We will try to convert the column to float.\n",
    "    ```python\n",
    "    try:\n",
    "        shop_behav['Review Rating'] = shop_behav['Review Rating'].astype('float')\n",
    "    except ValueError as e:\n",
    "        print(f\"Error encountered: {e}\")\n",
    "    ```\n",
    "    - This block attempts to directly convert the 'Review Rating' column to float.\n",
    "    - A `ValueError` is encountered because some values contain the string ' stars', which cannot be converted to float.\n",
    "    - The error message is printed to identify the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to directly convert 'Review Rating' to float\n",
    "try:\n",
    "    shop_behav['Review Rating'] = shop_behav['Review Rating'].astype('float')\n",
    "except ValueError as e:\n",
    "    print(f\"Error encountered: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3838052c-44bd-4ed3-b857-e4d431c87d63",
   "metadata": {},
   "source": [
    "2. Now we'll properly format the column before converting it to a string\n",
    "    ```python\n",
    "    shop_behav['Review Rating'] = shop_behav['Review Rating'].str.rstrip(' stars').astype('float') \n",
    "    ```\n",
    "    - **shop_behav['Review Rating'].str.rstrip(' stars')**: Removes the trailing ' stars' string from each value in the 'Review Rating' column.\n",
    "    - **astype('float')**: Converts the cleaned string values to float.\n",
    "    - This ensures the 'Review Rating' column has the correct numerical data type.\n",
    "\n",
    "3. **Displaying Data Types**:\n",
    "    ```python\n",
    "    shop_behav.dtypes\n",
    "    ```\n",
    "    - Displays the data types of all columns in the `shop_behav` DataFrame to verify the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c5a07-0a3c-4631-8f18-af9d77344596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the 'Review Rating' column by removing the ' stars' string and converting to float\n",
    "shop_behav['Review Rating'] = shop_behav['Review Rating'].str.rstrip(' stars').astype('float') \n",
    "\n",
    "# Display data types of the columns\n",
    "shop_behav.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfb4628-72cf-431a-b7fd-814c8c8d1c25",
   "metadata": {},
   "source": [
    "Again checking the same rows of the column, we can see that the data type is now `float64`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b671eb-13a8-41e5-90a2-7ccd1a03b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_behav['Review Rating'][55:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1885a096",
   "metadata": {},
   "source": [
    "## 2. Data Wrangling\n",
    "\n",
    "Data wrangling, also known as data munging, involves transforming and mapping data from its raw form into another format to make it more appropriate and valuable for analysis. This process includes merging datasets, reshaping data, and creating new variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be9ad07",
   "metadata": {},
   "source": [
    "### Merging CSV Files\n",
    "When working with large datasets, data may be split across multiple files. Merging these files into a single dataset is often necessary. This involves reading each file and concatenating them into one dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8643fba9-bb49-4ca9-b002-eb19315515e5",
   "metadata": {},
   "source": [
    "We first load the NOAA dataset and list the files it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933facce-31e5-4804-aac6-f84da087411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List and load CSV files for the dataset\n",
    "folder_path = '../Datasets/NOAA_Weather'\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42577288-939e-4a0d-89fc-1a3bfe1b6788",
   "metadata": {},
   "source": [
    "We can see that it has three different CSV files, which are basically weather data recordings from three different stations. Let's suppose we want to perform an analysis for all three stations, it is much more efficient to concatenate all of them into one and then perform the required tasks.\n",
    "\n",
    "The below code concatenates multiple CSV files into a single DataFrame.\n",
    "\n",
    "- **pd.concat([...])**: Concatenates the list of DataFrames into a single DataFrame.\n",
    "- **[pd.read_csv(os.path.join(folder_path, file)) for file in csv_files]**: This list comprehension reads each CSV file in the `csv_files` list and returns a list of DataFrames.\n",
    "    - **os.path.join(folder_path, file)**: Constructs the full file path for each CSV file.\n",
    "    - **pd.read_csv(...)**: Reads the CSV file into a DataFrame.\n",
    "- **ignore_index=True**: Ensures that the resulting DataFrame has a new, continuous index.\n",
    "\n",
    "The result is a single DataFrame, `noaa`, containing the data from all the CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b1b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and concatenate all CSV files\n",
    "noaa = pd.concat([pd.read_csv(os.path.join(folder_path, file)) for file in csv_files], ignore_index=True)\n",
    "noaa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f9702a-bd67-47a7-8db0-37dd6e627543",
   "metadata": {},
   "source": [
    "To verify that `noaa` indeed has all three stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91946a62-c9b4-49d8-ab1e-2c877617e028",
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa['STATION'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e646b9f2",
   "metadata": {},
   "source": [
    "### Creating New Columns\n",
    "Creating new columns from existing data can provide additional insights or make data analysis easier. This can involve operations like arithmetic transformations, conditional logic, or feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de315e-7842-4b32-a38c-0e9ed1e3d8c4",
   "metadata": {},
   "source": [
    "This code creates a new column 'COORDINATES' in the `noaa` DataFrame by concatenating the 'LATITUDE' and 'LONGITUDE' columns as strings.\n",
    "\n",
    "- **noaa['LATITUDE'].astype('str')**: Converts the 'LATITUDE' column to strings.\n",
    "- **noaa['LONGITUDE'].astype('str')**: Converts the 'LONGITUDE' column to strings.\n",
    "- **noaa['LATITUDE'].astype('str') + ',' + noaa['LONGITUDE'].astype('str')**: Concatenates the latitude and longitude values with a comma in between to form coordinate strings.\n",
    "- **noaa['COORDINATES']**: Assigns the resulting coordinate strings to a new column 'COORDINATES' in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f9bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column \"Coordinates\", which is \"Latitude, Longitude\"\n",
    "noaa['COORDINATES'] = noaa['LATITUDE'].astype('str') + ',' + noaa['LONGITUDE'].astype('str')\n",
    "noaa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23290b5",
   "metadata": {},
   "source": [
    "## 3. Data Analysis\n",
    "\n",
    "In this section, we will perform various data analysis tasks on the Yelp reviews dataset. This includes descriptive statistics, correlation analysis, grouping and aggregation, and trend analysis.\n",
    "\n",
    "Let's first load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3403c04f-0e97-48c7-81d6-ea563290e0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../Datasets/Yelp_Reviews/reviews.csv'\n",
    "reviews = pd.read_csv(file_path)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2074cd-6790-4ee5-8f9d-b6debf966724",
   "metadata": {},
   "source": [
    "### Distribution of Ratings\n",
    "\n",
    "We analyze the distribution of ratings in the Yelp reviews dataset. Understanding the distribution of ratings can provide insights into customer satisfaction and help identify patterns or trends in the feedback.\n",
    "\n",
    "- **rating_distribution = reviews['stars'].value_counts().sort_index()**:\n",
    "    - **reviews['stars']**: Select the 'stars' column from the DataFrame `reviews`, which contains the ratings given in the reviews.\n",
    "    - **value_counts()**: Counts the occurrence of each unique rating value, giving us the number of reviews for each rating.\n",
    "    - **sort_index()**: Sorts the counts by the rating values (index) in ascending order.\n",
    "\n",
    "- **rating_distribution**:\n",
    "    - This variable now holds a Series with the count of reviews for each rating, sorted by the rating values. It provides a clear view of how many reviews were given for each rating level (e.g., 1 star, 2 stars, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19062529-59f3-4613-8f2b-450b11057b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Ratings\n",
    "rating_distribution = reviews['stars'].value_counts().sort_index()\n",
    "rating_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8bd291-112a-4043-b223-e65b5273e71c",
   "metadata": {},
   "source": [
    "### Useful Reviews\n",
    "\n",
    "This code provides a statistical summary of the 'useful' ratings in the Yelp reviews dataset. The 'useful' ratings indicate how many users found a review helpful. Analyzing this data helps understand the general usefulness of reviews from the perspective of other users.\n",
    "\n",
    "- **useful_distribution = reviews['useful'].describe()**:\n",
    "    - **reviews['useful']**: Selects the 'useful' column from the DataFrame `reviews`, which contains the count of how many users marked each review as useful.\n",
    "    - **describe()**: Generates a summary of statistics for the 'useful' column, including count, mean, standard deviation, minimum, 25th percentile, median (50th percentile), 75th percentile, and maximum values.\n",
    "\n",
    "- **useful_distribution**:\n",
    "    - This variable now holds a Series with the statistical summary of the 'useful' ratings. It provides insights into the distribution and central tendencies of how useful users find the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3550fb49-fca9-46ba-aab6-b34457f5ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Reviews\n",
    "useful_distribution = reviews['useful'].describe()\n",
    "useful_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ec6740-0f3e-4cd1-b794-411c575eb81c",
   "metadata": {},
   "source": [
    "### Review Length vs Useful Votes\n",
    "\n",
    "Here we analyze the relationship between the length of a review and the number of useful votes it receives. By examining this relationship, we can understand if longer reviews tend to be more useful to readers.\n",
    "\n",
    "- **reviews['review_length'] = reviews['text'].apply(len)**:\n",
    "    - **reviews['text']**: Selects the 'text' column from the DataFrame `reviews`, which contains the review texts.\n",
    "    - **apply(len)**: Applies the `len` function to each review text, calculating the length of each review in terms of the number of characters.\n",
    "    - **reviews['review_length']**: Creates a new column 'review_length' in the DataFrame `reviews` to store the length of each review.\n",
    "\n",
    "- **review_length_vs_useful = df[['review_length', 'useful']]**:\n",
    "    - Selects the 'review_length' and 'useful' columns from the DataFrame `reviews` and creates a new DataFrame `review_length_vs_useful` containing these two columns.\n",
    "\n",
    "- **review_length_vs_useful.head()**:\n",
    "    - Displays the first five rows of the `review_length_vs_useful` DataFrame. This provides a quick look at the data, showing the length of the reviews alongside the number of useful votes they received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ac0008-5d7c-4e7b-bc87-a637a3cc88b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review Length vs Useful Votes\n",
    "reviews['review_length'] = reviews['text'].apply(len)\n",
    "review_length_vs_useful = reviews[['review_length', 'useful']]\n",
    "review_length_vs_useful.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e384e-877b-4e65-b831-98d057afb8c7",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "\n",
    "We apply sentiment analysis to the review texts to classify them as Positive, Negative, or Neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8663f2af-2448-4874-85e5-022d09b4eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Function to classify sentiment\n",
    "def classify_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif analysis.sentiment.polarity < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply sentiment analysis to the text column\n",
    "reviews['sentiment'] = reviews['text'].apply(classify_sentiment)\n",
    "sentiment_distribution = reviews['sentiment'].value_counts()\n",
    "sentiment_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c098ce",
   "metadata": {},
   "source": [
    "## 4. Data Visualization\n",
    "\n",
    "In this section, we will create various plots to visualize the data and the results of our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8906f45d-5236-4d29-9fed-1750c57ba05d",
   "metadata": {},
   "source": [
    "### Bar Chart for Distribution of Ratings\n",
    "on\n",
    "This plot is a bar chart that visualizes the distribution of star ratings in the Yelp reviews dataset. It shows how frequently each star rating (1 to 5 stars) is given, providing insights into overall customer satisfactiotion\n",
    "\n",
    "- **import matplotlib.pyplot as plt**:\n",
    "    - Imports the `matplotlib.pyplot` module, which is used for creating visualizations.\n",
    "\n",
    "- **plt.figure(figsize=(10, 6))**:\n",
    "    - Creates a new figure with a specified size of 10 inches in width and 6 inches in height.\n",
    "\n",
    "- **reviews['stars'].value_counts().sort_index().plot(kind='bar')**:\n",
    "    - **reviews['stars']**: Selects the 'stars' column from the DataFrame `reviews`.\n",
    "    - **value_counts()**: Counts the occurrence of each unique rating value.\n",
    "    - **sort_index()**: Sorts the counts by the rating values in ascending order.\n",
    "    - **plot(kind='bar')**: Creates a bar plot of the sorted rating counts.\n",
    "\n",
    "- **plt.xlabel('Star Ratings')**:\n",
    "    - Sets the label for the x-axis to 'Star Ratings'.\n",
    "\n",
    "- **plt.ylabel('Frequency')**:\n",
    "    - Sets the label for the y-axis to 'Frequency'.\n",
    "\n",
    "- **plt.title('Distribution of Star Ratings')**:\n",
    "    - Sets the title of the plot to 'Distribution of Star Ratings'.\n",
    "\n",
    "- **plt.show()**:\n",
    "   - Displays the bar chart.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715730d0-b4d4-4204-a952-809d24e00335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bar Chart for Distribution of Ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "reviews['stars'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.xlabel('Star Ratings')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Star Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f13cf8-4e87-4e42-afea-db7089fbcc2e",
   "metadata": {},
   "source": [
    "### Scatter Plot for Review Length vs Useful Votes\n",
    "\n",
    "This plot is a scatter plot that visualizes the relationship between the length of reviews and the number of useful votes they receive. Each point represents a review, with its position determined by the review's length and the number of useful votes. This helps in identifying any patterns or correlations between these two variables.\n",
    "\n",
    "- **plt.scatter(reviews['review_length'], reviews['useful'], alpha=0.5)**:\n",
    "    - **plt.scatter()**: Creates a scatter plot.\n",
    "    - **reviews['review_length']**: Specifies the x-axis data, which is the length of the reviews.\n",
    "    - **reviews['useful']**: Specifies the y-axis data, which is the number of useful votes.\n",
    "    - **alpha=0.5**: Sets the transparency level of the points to 0.5, making it easier to see overlapping points.\n",
    "\n",
    "- **plt.xlabel('Review Length')**:\n",
    "    - Sets the label for the x-axis to 'Review Length'.\n",
    "\n",
    "- **plt.ylabel('Number of Useful Votes')**:\n",
    "    - Sets the label for the y-axis to 'Number of Useful Votes'.\n",
    "\n",
    "- **plt.title('Review Length vs Useful Votes')**:\n",
    "    - Sets the title of the plot to 'Review Length vs Useful Votes'.\n",
    "\n",
    "- **plt.show()**:\n",
    "    - Displays the scatter plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1135a67e-0096-4bce-9fee-577ae7b31a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot for Review Length vs Useful Votes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(reviews['review_length'], reviews['useful'], alpha=0.5)\n",
    "plt.xlabel('Review Length')\n",
    "plt.ylabel('Number of Useful Votes')\n",
    "plt.title('Review Length vs Useful Votes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f490e7-d207-4220-b501-802f2cf9addc",
   "metadata": {},
   "source": [
    "### Line Chart for Average Ratings Over Time\n",
    "n\n",
    "This plot is a line chart that visualizes the average star rating of reviews over time. It shows how the average rating has changed monthly, allowing for the identification of trends and patterns in customer satisfaction over the observed perioheight.\n",
    "\n",
    "- **monthly_avg_rating.plot()**:\n",
    "    - Plots the `monthly_avg_rat from the Data Analysis sectioning` Series, which contains the average star rating for each month, as a line chart.\n",
    "\n",
    "- **plt.xlabel('Date')**:\n",
    "    - Sets the label for the x-axis to 'Date'.\n",
    "\n",
    "- **plt.ylabel('Average Star Rating')**:\n",
    "    - Sets the label for the y-axis to 'Average Star Rating'.\n",
    "\n",
    "- **plt.title('Average Star Rating Over Time')**:\n",
    "    - Sets the title of the plot to 'Average Stasplays the line chart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f4dbb-1bf0-44c6-bbe6-030455d4d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line Chart for Average Ratings Over Time\n",
    "plt.figure(figsize=(10, 6))\n",
    "monthly_avg_rating.plot()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Star Rating')\n",
    "plt.title('Average Star Rating Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5364c4-70fd-46cc-ae5e-620a61fce238",
   "metadata": {},
   "source": [
    "The breaks in the lines indicate that no data was available for these months."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cb2663-0401-4878-985e-2b69ca590d8c",
   "metadata": {},
   "source": [
    "### Pie Chart for Sentiment Distribution\n",
    "\n",
    "This plot is a pie chart that visualizes the distribution of sentiment classifications (Positive, Negative, Neutral) in the Yelp reviews dataset. It shows the proportion of each sentiment category, providing insights into the overall sentiment of the reviews.\n",
    "\n",
    "- **sentiment_counts = reviews['sentiment'].value_counts()**:\n",
    "    - Counts the occurrences of each sentiment category in the 'sentiment' column of the DataFrame `reviews`, which we created in the Data Analysis section.\n",
    "    - **sentiment_counts**: Stores the counts of each sentiment.\n",
    "\n",
    "- **plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=140)**:\n",
    "    - **plt.pie()**: Creates a pie chart.\n",
    "    - **sentiment_counts**: Provides the data for the pie chart (the counts of each sentiment).\n",
    "    - **labels=sentiment_counts.index**: Labels each slice of the pie chart with the sentiment categories.\n",
    "    - **autopct='%1.1f%%'**: Displays the percentage of each slice with one decimal place.\n",
    "    - **startangle=140**: Rotates the start of the pie chart to 140 degrees for better visual presentation.\n",
    "\n",
    "- **plt.title('Sentiment Distribution of Reviews')**:\n",
    "    - Sets the title of the plot to 'Sentiment Distribution of Reviews'.\n",
    "\n",
    "- **plt.show()**:\n",
    "    - Displays the pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff05370-3d31-4b05-a0f6-73e4747187a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie Chart for Sentiment Distribution\n",
    "# Count the occurrences of each sentiment\n",
    "sentiment_counts = reviews['sentiment'].value_counts()\n",
    "\n",
    "# Plot the pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Sentiment Distribution of Reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de95caf7-5ecd-469a-b453-86fb230ee179",
   "metadata": {},
   "source": [
    "### Heat Map for Numeric Columns\n",
    "\n",
    "This plot is a heat map that visualizes the correlation between numeric columns in the Yelp reviews dataset. The heat map shows the strength and direction of the relationships between pairs of variables, helping to identify patterns and potential dependencies.\n",
    "\n",
    "- **import seaborn as sns**:\n",
    "    - Imports the `seaborn` library, which is used for creating advanced visualizations.\n",
    "\n",
    "- **numeric_cols = ['stars', 'useful', 'funny', 'cool']**:\n",
    "    - Defines a list of numeric columns that will be included in the heat map.\n",
    "\n",
    "- **corr_matrix = df[numeric_cols].corr()**:\n",
    "    - Computes the correlation matrix for the selected numeric columns.\n",
    "    - **df[numeric_cols]**: Selects the specified numeric columns from the DataFrame `df`.\n",
    "    - **corr()**: Calculates the pairwise correlation coefficients between the columns.\n",
    "\n",
    "- **plt.figure(figsize=(10, 8))**:\n",
    "    - Creates a new figure with a specified size of 10 inches in width and 8 inches in height.\n",
    "\n",
    "- **sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')**:\n",
    "    - **sns.heatmap()**: Plots the heat map.\n",
    "    - **corr_matrix**: Provides the data for the heat map (the correlation matrix).\n",
    "    - **annot=True**: Displays the correlation coefficients on the heat map.\n",
    "    - **cmap='coolwarm'**: Uses the 'coolwarm' colormap for the heat map.\n",
    "    - **fmt='.2f'**: Formats the correlation coefficients to two decimal places.\n",
    "\n",
    "- **plt.title('Correlation Heatmap of Numeric Columns')**:\n",
    "    - Sets the title of the plot to 'Correlation Heatmap of Numeric Columns'.\n",
    "\n",
    "- **plt.show()**:\n",
    "    - Displays the heat map.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce50850-7178-4afb-9cb1-4da19e007245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Heat Map for Numeric Columns\n",
    "# Select numeric columns for the heat map\n",
    "numeric_cols = ['stars', 'useful', 'funny', 'cool']\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = reviews[numeric_cols].corr()\n",
    "\n",
    "# Plot the heat map\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap of Numeric Columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fa22b8-45d4-427a-a607-8081f390a44c",
   "metadata": {},
   "source": [
    "## 4. Reflection Exercise\n",
    "\n",
    "Based on your inputs from the previous two exercises, here is your personalized prompt that you can use with a Generative AI model of your choice to obtain a comprehensive data analysis guide tailored to your needs. This guide will help you navigate through your data analysis tasks with ease and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a9f0e-04e1-4e82-a838-2d6f74390d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..\\Prompts\\Prompt.txt', 'r') as file:\n",
    "    prompt = file.read()\n",
    "prompt\n",
    "\n",
    "lines = prompt.splitlines()\n",
    "\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ff5570-6dd8-4b8b-ab04-95f96f88057f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
