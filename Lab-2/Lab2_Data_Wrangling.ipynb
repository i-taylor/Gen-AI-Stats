{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1698b99",
   "metadata": {},
   "source": [
    "# Lab 2: Data Wrangling, Analysis, and Visualization\n",
    "\n",
    "## Introduction\n",
    "This laboratory exercise is divided into three parts. The first part focuses on data wrangling. The second part guides you through data analysis. In the final part, you will explore data visualization. Upon completion of these sections, there is again a reflection exercise that we strongly encourage you to undertake. These are crucial techniques in data science to clean, prepare, analyze, and present data effectively. You will be working with three distinct datasets, each presenting unique challenges and learning opportunities.\n",
    "\n",
    "### Overview of the Lab Topics\n",
    "- **Data Wrangling**: Handling missing values, removing duplicates, converting data types, merging multiple CSV files, and creating new columns\n",
    "- **Data Analysis**: Performing descriptive statistics, correlation analysis, grouping and aggregation, and trend analysis.\n",
    "- **Data Visualization**: Creating various types of plots to visualize the data.\n",
    "\n",
    "This lab will take a while to go through, so don't be afraid to take breaks. And remember to use an AI-copilot as you are going through this to ask questions about bits of code that you don't understand.\n",
    "\n",
    "You can copy the code into your GenAI tool and ask questions like \"Are there other ways of doing this?\" \"Can you explain the pros and cons of using this option?\" \"Can you breakdown this code for me in detail?\"\n",
    "\n",
    "I encourage you to do this to make the most out of the lab! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65190617-4cb0-46cf-be12-61fc8fb06d0e",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "Data wrangling includes preprocessing and cleaning steps that are critical in the data analysis pipeline. The quality of data directly impacts the quality of insights that can be derived from it. Preprocessing involves transforming raw data into a clean and usable format. Cleaning involves handling missing values, correcting errors, and preparing the data for analysis.\n",
    "\n",
    "### Handling Missing Values\n",
    "Missing values are common in datasets and can significantly affect the results of your analysis. Common strategies to handle missing values include:\n",
    "- **Removal**: Removing rows or columns with missing values.\n",
    "- **Imputation**: Filling missing values with a specific value such as the mean, median, or mode of the column.\n",
    "- **Prediction**: Using machine learning models to predict missing values based on other features.\n",
    "\n",
    "Let's start by importing the required libraries and loading the CSV file for `shopping_behavior` dataset in `Kaggle Ecommerce` and examining the data to identify errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c14ae3-e570-4a9f-b845-af29fa37927d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Item Purchased</th>\n",
       "      <th>Category</th>\n",
       "      <th>Purchase Amount (USD)</th>\n",
       "      <th>Location</th>\n",
       "      <th>Size</th>\n",
       "      <th>Color</th>\n",
       "      <th>Season</th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Subscription Status</th>\n",
       "      <th>Shipping Type</th>\n",
       "      <th>Discount Applied</th>\n",
       "      <th>Promo Code Used</th>\n",
       "      <th>Previous Purchases</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Frequency of Purchases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>Male</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>53</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>L</td>\n",
       "      <td>Gray</td>\n",
       "      <td>Winter</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Express</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>14</td>\n",
       "      <td>Venmo</td>\n",
       "      <td>Fortnightly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>Sweater</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>64</td>\n",
       "      <td>Maine</td>\n",
       "      <td>L</td>\n",
       "      <td>Maroon</td>\n",
       "      <td>Winter</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Express</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Fortnightly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>Male</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>73</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>S</td>\n",
       "      <td>Maroon</td>\n",
       "      <td>Spring</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Free Shipping</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>23</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Weekly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>Male</td>\n",
       "      <td>Sandals</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>90</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>M</td>\n",
       "      <td>Maroon</td>\n",
       "      <td>Spring</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Next Day Air</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>49</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>Weekly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>49</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>M</td>\n",
       "      <td>Turquoise</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2.7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Free Shipping</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>31</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>Annually</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer ID  Age Gender Item Purchased  Category Purchase Amount (USD)  \\\n",
       "0            1   55   Male         Blouse  Clothing                    53   \n",
       "1            2   19   Male        Sweater  Clothing                    64   \n",
       "2            3   50   Male          Jeans  Clothing                    73   \n",
       "3            4   21   Male        Sandals  Footwear                    90   \n",
       "4            5   45   Male         Blouse  Clothing                    49   \n",
       "\n",
       "        Location Size      Color  Season Review Rating Subscription Status  \\\n",
       "0       Kentucky    L       Gray  Winter           3.1                 Yes   \n",
       "1          Maine    L     Maroon  Winter           3.1                 Yes   \n",
       "2  Massachusetts    S     Maroon  Spring           3.1                 Yes   \n",
       "3   Rhode Island    M     Maroon  Spring           3.5                 Yes   \n",
       "4         Oregon    M  Turquoise  Spring           2.7                 Yes   \n",
       "\n",
       "   Shipping Type Discount Applied Promo Code Used  Previous Purchases  \\\n",
       "0        Express              Yes             Yes                  14   \n",
       "1        Express              Yes             Yes                   2   \n",
       "2  Free Shipping              Yes             Yes                  23   \n",
       "3   Next Day Air              Yes             Yes                  49   \n",
       "4  Free Shipping              Yes             Yes                  31   \n",
       "\n",
       "  Payment Method Frequency of Purchases  \n",
       "0          Venmo            Fortnightly  \n",
       "1           Cash            Fortnightly  \n",
       "2    Credit Card                 Weekly  \n",
       "3         PayPal                 Weekly  \n",
       "4         PayPal               Annually  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import os  # Module for interacting with the operating system\n",
    "import pandas as pd  # Library for data manipulation and analysis\n",
    "import numpy as np  # Library for numerical computations\n",
    "\n",
    "# Define the relative path to the dataset CSV file\n",
    "file_path = '../Datasets/Kaggle_Ecommerce/shopping_behavior.csv'\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "shop_behav = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "shop_behav.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e3fdb0-48ce-4999-9406-d3442ccd0b94",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "Identify and handle missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bc2e7a-95ce-44bf-8d94-0cc751091287",
   "metadata": {},
   "source": [
    "This code checks for missing values in the `shop_behav` DataFrame.\n",
    "\n",
    "- **shop_behav.isnull()**: Identifies all the null (missing) values in the DataFrame.\n",
    "- **sum()**: Counts the total number of missing values in each column.\n",
    "\n",
    "The result shows the number of missing values per column, helping us understand the extent of missing data in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73273b0e-a2f1-463c-8023-53a16727ccdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer ID               0\n",
       "Age                       0\n",
       "Gender                    0\n",
       "Item Purchased            0\n",
       "Category                  0\n",
       "Purchase Amount (USD)     1\n",
       "Location                  0\n",
       "Size                      0\n",
       "Color                     2\n",
       "Season                    0\n",
       "Review Rating             1\n",
       "Subscription Status       0\n",
       "Shipping Type             0\n",
       "Discount Applied          0\n",
       "Promo Code Used           0\n",
       "Previous Purchases        0\n",
       "Payment Method            0\n",
       "Frequency of Purchases    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify missing values\n",
    "shop_behav.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c5fed8-956f-4462-bc4b-150da3e65da9",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 10px;\">\n",
    "\n",
    "🤖 \n",
    "<br>\n",
    "**Now that you know which columns have null values, ask Generative AI about various methods of handling this. Remember to ask about the pros and the cons of different options.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a12323b-86e4-489c-a551-322ce72c3764",
   "metadata": {},
   "source": [
    "This code handles missing values in the `shop_behav` DataFrame. Here, we are filling the missing values with the mean of the corresponding column.\n",
    "\n",
    "- **missing_cols**: Identifies columns with any missing values.\n",
    "- **for col in missing_cols**: Iterates through each column with missing values.\n",
    "    - **if shop_behav[col].dtype in [np.float64, np.int64]**: Checks if the column is numerical.\n",
    "    - **shop_behav[col].fillna(shop_behav[col].mean(), inplace=True)**: Fills missing values in numerical columns with the column mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db61676a-bf39-4df1-afb9-50245effb9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with missing values\n",
    "missing_cols = shop_behav.columns[shop_behav.isnull().any()]\n",
    "\n",
    "# Fill missing values in numerical columns with the mean value of those columns\n",
    "for col in missing_cols:\n",
    "    # Check if the column's data type is either float64 or int64 (i.e., a numerical column)\n",
    "    if shop_behav[col].dtype in [np.float64, np.int64]:\n",
    "        # Replace NaN values with the mean of the column\n",
    "        shop_behav[col].fillna(shop_behav[col].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d997335f-cfc2-4020-b502-d048adc1550d",
   "metadata": {},
   "source": [
    "We again check for missing values, and as can be seen, there are none left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3a3622c-640c-40e2-94d8-398fd2481b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer ID               0\n",
       "Age                       0\n",
       "Gender                    0\n",
       "Item Purchased            0\n",
       "Category                  0\n",
       "Purchase Amount (USD)     1\n",
       "Location                  0\n",
       "Size                      0\n",
       "Color                     2\n",
       "Season                    0\n",
       "Review Rating             1\n",
       "Subscription Status       0\n",
       "Shipping Type             0\n",
       "Discount Applied          0\n",
       "Promo Code Used           0\n",
       "Previous Purchases        0\n",
       "Payment Method            0\n",
       "Frequency of Purchases    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rechecking for missing values\n",
    "shop_behav.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d381c2-ad94-44c9-9499-cdf098b1a024",
   "metadata": {},
   "source": [
    "### Removing Duplicates\n",
    "Duplicate records can skew your analysis and lead to incorrect insights. Removing duplicates ensures that each record in your dataset is unique. This is typically done by identifying and removing rows that have identical values across all columns.\n",
    "\n",
    "This code checks for duplicate rows in the `shov_behav` DataFrame.\n",
    "\n",
    "- **data2.duplicated()**: Identifies duplicate rows.\n",
    "- **sum()**: Counts the total number of duplicate rows in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e813005-dd64-4ea7-b404-95d4bd079227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify duplicates\n",
    "shop_behav.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd652bd-8d98-4ade-901b-6ea42ed4d657",
   "metadata": {},
   "source": [
    "This indicates that the dataset has one duplicate row. We will fix it now.\n",
    "\n",
    "- **shop_behav.drop_duplicates(inplace=True)**: Removes duplicate rows from the DataFrame and updates `shop_behav` in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a7002d9-f5f9-479e-964d-4d2022673128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "shop_behav.drop_duplicates(inplace=True)\n",
    "shop_behav.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf72bc9-c2a7-4946-b37d-759eee326a3f",
   "metadata": {},
   "source": [
    "The dataset now has `0` duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae4ba5-fc3b-4eff-9662-a04ef3677e5a",
   "metadata": {},
   "source": [
    "### Data Type Conversion\n",
    "Ensuring that each column has the correct data type is crucial for accurate analysis. In a DataFrame, each column must contain only one type of data. This is because DataFrames are like tables where each column needs to be uniform in type. For example:\n",
    "- Dates should be stored as date objects.\n",
    "- Numbers should be in numerical formats like integers or floats.\n",
    "- Categorical data should be stored as category types.\n",
    "Let's look at an example with the 'Review Rating' column. This column should contain numbers (floats), but due to some rows having extra text like ' stars', its data type is currently a string (object). Here's what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55b6b1a1-b2ab-4b68-b16b-71766b587e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55            3\n",
       "56          4.7\n",
       "57    4.4 stars\n",
       "58          4.2\n",
       "59          4.6\n",
       "Name: Review Rating, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_behav['Review Rating'][55:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b835c3",
   "metadata": {},
   "source": [
    "### Steps to Correct Data Type Conversion\n",
    "\n",
    "1. **Try to Convert the Column to Float**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24e50dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered: could not convert string to float: '4.4 stars'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    shop_behav['Review Rating'] = shop_behav['Review Rating'].astype('float')\n",
    "except ValueError as e:\n",
    "    print(f\"Error encountered: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07053e4",
   "metadata": {},
   "source": [
    "- This code tries to change 'Review Rating' to float type.\n",
    "- It fails because some values have ' stars', which can't be converted to a number.\n",
    "- The error message tells us there's a problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d6d929",
   "metadata": {},
   "source": [
    "\n",
    "2. **Find the Problematic Rows**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85d13ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Customer ID  Age Gender Item Purchased   Category Purchase Amount (USD)  \\\n",
      "57           58   21   Male           Coat  Outerwear                    64   \n",
      "\n",
      "         Location Size  Color  Season Review Rating Subscription Status  \\\n",
      "57  West Virginia    M  White  Summer     4.4 stars                 Yes   \n",
      "\n",
      "   Shipping Type Discount Applied Promo Code Used  Previous Purchases  \\\n",
      "57  Store Pickup              Yes             Yes                  17   \n",
      "\n",
      "   Payment Method Frequency of Purchases  \n",
      "57     Debit Card            Fortnightly  \n"
     ]
    }
   ],
   "source": [
    "# Create a function to check if a value can be converted to float\n",
    "def can_convert_to_float(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Apply the function to each value in 'Review Rating' and find problematic rows\n",
    "problematic_rows = shop_behav[~shop_behav['Review Rating'].apply(can_convert_to_float)]\n",
    "print(problematic_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b782763",
   "metadata": {},
   "source": [
    "- This code finds rows where 'Review Rating' has the text 'stars'.\n",
    "- Printing these rows helps us see where the issue is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3b7ad5",
   "metadata": {},
   "source": [
    "3. **Clean the 'Review Rating' Column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4edc9888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ' stars' from 'Review Rating'\n",
    "shop_behav['Review Rating'] = shop_behav['Review Rating'].str.replace(' stars', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6497e51",
   "metadata": {},
   "source": [
    "- This line removes ' stars' from all values in the 'Review Rating' column.\n",
    "- Now the column should have only numbers as strings, ready to convert to float."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660e7ced-b5fe-4256-9300-17d15db9604f",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 10px;\">\n",
    "\n",
    "🤖 \n",
    "<br>\n",
    "**Ask Generative AI the ways you can format these kinds of strings**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ecb5e7",
   "metadata": {},
   "source": [
    "\n",
    "4. **Displaying Data Types**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9d01cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer ID                int64\n",
       "Age                        int64\n",
       "Gender                    object\n",
       "Item Purchased            object\n",
       "Category                  object\n",
       "Purchase Amount (USD)     object\n",
       "Location                  object\n",
       "Size                      object\n",
       "Color                     object\n",
       "Season                    object\n",
       "Review Rating             object\n",
       "Subscription Status       object\n",
       "Shipping Type             object\n",
       "Discount Applied          object\n",
       "Promo Code Used           object\n",
       "Previous Purchases         int64\n",
       "Payment Method            object\n",
       "Frequency of Purchases    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_behav.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4676ff63",
   "metadata": {},
   "source": [
    "\n",
    "- Displays the data types of all columns in the `shop_behav` DataFrame to verify the conversion. We see that Rating is still an object, so we have to convert it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f2c5a07-0a3c-4631-8f18-af9d77344596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer ID                 int64\n",
       "Age                         int64\n",
       "Gender                     object\n",
       "Item Purchased             object\n",
       "Category                   object\n",
       "Purchase Amount (USD)      object\n",
       "Location                   object\n",
       "Size                       object\n",
       "Color                      object\n",
       "Season                     object\n",
       "Review Rating             float64\n",
       "Subscription Status        object\n",
       "Shipping Type              object\n",
       "Discount Applied           object\n",
       "Promo Code Used            object\n",
       "Previous Purchases          int64\n",
       "Payment Method             object\n",
       "Frequency of Purchases     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixing the 'Review Rating' column by removing the ' stars' string and converting to float\n",
    "shop_behav['Review Rating'] = shop_behav['Review Rating'].str.rstrip(' stars').astype('float') \n",
    "\n",
    "# Display data types of the columns\n",
    "shop_behav.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfb4628-72cf-431a-b7fd-814c8c8d1c25",
   "metadata": {},
   "source": [
    "Again checking the same rows of the column, we can see that the data type is now `float64`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20b671eb-13a8-41e5-90a2-7ccd1a03b8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55    3.0\n",
       "56    4.7\n",
       "57    4.4\n",
       "58    4.2\n",
       "59    4.6\n",
       "Name: Review Rating, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_behav['Review Rating'][55:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be9ad07",
   "metadata": {},
   "source": [
    "### Merging CSV Files\n",
    "When working with large datasets, data may be split across multiple files. Merging these files into a single dataset is often necessary. This involves reading each file and concatenating them into one dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8643fba9-bb49-4ca9-b002-eb19315515e5",
   "metadata": {},
   "source": [
    "We first load the NOAA dataset and list the files it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "933facce-31e5-4804-aac6-f84da087411f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['31285099999.csv', '72484653123.csv', '99999926563.csv']\n"
     ]
    }
   ],
   "source": [
    "folder_path = '../Datasets/NOAA_Weather'  # Define the path to the folder containing the CSV files\n",
    "\n",
    "# List comprehension to find all files in the folder that end with '.csv'\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "print(csv_files)  # Print the list of CSV files to check which files were found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42577288-939e-4a0d-89fc-1a3bfe1b6788",
   "metadata": {},
   "source": [
    "We can see that it has three different CSV files, which are basically weather data recordings from three different stations. Let's suppose we want to perform an analysis for all three stations, it is much more efficient to concatenate all of them into one and then perform the required tasks.\n",
    "\n",
    "The below code concatenates multiple CSV files into a single DataFrame.\n",
    "\n",
    "- **pd.concat([...])**: Concatenates the list of DataFrames into a single DataFrame.\n",
    "- **[pd.read_csv(os.path.join(folder_path, file)) for file in csv_files]**: This list comprehension reads each CSV file in the `csv_files` list and returns a list of DataFrames.\n",
    "    - **os.path.join(folder_path, file)**: Constructs the full file path for each CSV file.\n",
    "    - **pd.read_csv(...)**: Reads the CSV file into a DataFrame.\n",
    "- **ignore_index=True**: Ensures that the resulting DataFrame has a new, continuous index.\n",
    "\n",
    "The result is a single DataFrame, `noaa`, containing the data from all the CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b2b1b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>REPORT_TYPE</th>\n",
       "      <th>CALL_SIGN</th>\n",
       "      <th>QUALITY_CONTROL</th>\n",
       "      <th>...</th>\n",
       "      <th>CU2</th>\n",
       "      <th>CU3</th>\n",
       "      <th>CV1</th>\n",
       "      <th>CV2</th>\n",
       "      <th>CV3</th>\n",
       "      <th>CW1</th>\n",
       "      <th>GH1</th>\n",
       "      <th>IB2</th>\n",
       "      <th>KF1</th>\n",
       "      <th>OB1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31285099999</td>\n",
       "      <td>2024-01-01T00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>54.5</td>\n",
       "      <td>134.416667</td>\n",
       "      <td>62.0</td>\n",
       "      <td>UDSKOE, RS</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>99999</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31285099999</td>\n",
       "      <td>2024-01-01T03:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>54.5</td>\n",
       "      <td>134.416667</td>\n",
       "      <td>62.0</td>\n",
       "      <td>UDSKOE, RS</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>99999</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31285099999</td>\n",
       "      <td>2024-01-01T06:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>54.5</td>\n",
       "      <td>134.416667</td>\n",
       "      <td>62.0</td>\n",
       "      <td>UDSKOE, RS</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>99999</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31285099999</td>\n",
       "      <td>2024-01-01T09:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>54.5</td>\n",
       "      <td>134.416667</td>\n",
       "      <td>62.0</td>\n",
       "      <td>UDSKOE, RS</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>99999</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31285099999</td>\n",
       "      <td>2024-01-01T12:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>54.5</td>\n",
       "      <td>134.416667</td>\n",
       "      <td>62.0</td>\n",
       "      <td>UDSKOE, RS</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>99999</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION                 DATE SOURCE  LATITUDE   LONGITUDE  ELEVATION  \\\n",
       "0  31285099999  2024-01-01T00:00:00      4      54.5  134.416667       62.0   \n",
       "1  31285099999  2024-01-01T03:00:00      4      54.5  134.416667       62.0   \n",
       "2  31285099999  2024-01-01T06:00:00      4      54.5  134.416667       62.0   \n",
       "3  31285099999  2024-01-01T09:00:00      4      54.5  134.416667       62.0   \n",
       "4  31285099999  2024-01-01T12:00:00      4      54.5  134.416667       62.0   \n",
       "\n",
       "         NAME REPORT_TYPE CALL_SIGN QUALITY_CONTROL  ...  CU2  CU3  CV1  CV2  \\\n",
       "0  UDSKOE, RS       FM-12     99999            V020  ...  NaN  NaN  NaN  NaN   \n",
       "1  UDSKOE, RS       FM-12     99999            V020  ...  NaN  NaN  NaN  NaN   \n",
       "2  UDSKOE, RS       FM-12     99999            V020  ...  NaN  NaN  NaN  NaN   \n",
       "3  UDSKOE, RS       FM-12     99999            V020  ...  NaN  NaN  NaN  NaN   \n",
       "4  UDSKOE, RS       FM-12     99999            V020  ...  NaN  NaN  NaN  NaN   \n",
       "\n",
       "   CV3  CW1  GH1  IB2  KF1  OB1  \n",
       "0  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and concatenate all CSV files\n",
    "noaa = pd.concat([pd.read_csv(os.path.join(folder_path, file)) for file in csv_files], ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "noaa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8754c91",
   "metadata": {},
   "source": [
    "- `pd.concat([...])` combines multiple DataFrames into a single DataFrame.\n",
    "- `[pd.read_csv(os.path.join(folder_path, file)) for file in csv_files]` reads each CSV file into a DataFrame and creates a list of these DataFrames.\n",
    "- `ignore_index=True` reindexes the combined DataFrame to have a continuous index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f9702a-bd67-47a7-8db0-37dd6e627543",
   "metadata": {},
   "source": [
    "To verify that `noaa` indeed has all three stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91946a62-c9b4-49d8-ab1e-2c877617e028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31285099999, 72484653123, 99999926563])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noaa['STATION'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e646b9f2",
   "metadata": {},
   "source": [
    "### Creating New Columns\n",
    "Creating new columns from existing data can provide additional insights or make data analysis easier. This can involve operations like arithmetic transformations, conditional logic, or feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de315e-7842-4b32-a38c-0e9ed1e3d8c4",
   "metadata": {},
   "source": [
    "This code creates a new column 'COORDINATES' in the `noaa` DataFrame by concatenating the 'LATITUDE' and 'LONGITUDE' columns as strings.\n",
    "\n",
    "- **noaa['LATITUDE'].astype('str')**: Converts the 'LATITUDE' column to strings.\n",
    "- **noaa['LONGITUDE'].astype('str')**: Converts the 'LONGITUDE' column to strings.\n",
    "- **noaa['LATITUDE'].astype('str') + ',' + noaa['LONGITUDE'].astype('str')**: Concatenates the latitude and longitude values with a comma in between to form coordinate strings.\n",
    "- **noaa['COORDINATES']**: Assigns the resulting coordinate strings to a new column 'COORDINATES' in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d48f9bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>REPORT_TYPE</th>\n",
       "      <th>CALL_SIGN</th>\n",
       "      <th>QUALITY_CONTROL</th>\n",
       "      <th>...</th>\n",
       "      <th>CU3</th>\n",
       "      <th>CV1</th>\n",
       "      <th>CV2</th>\n",
       "      <th>CV3</th>\n",
       "      <th>CW1</th>\n",
       "      <th>GH1</th>\n",
       "      <th>IB2</th>\n",
       "      <th>KF1</th>\n",
       "      <th>OB1</th>\n",
       "      <th>COORDINATES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31285099999</td>\n",
       "      <td>2024-01-01T00:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>54.5</td>\n",
       "      <td>134.416667</td>\n",
       "      <td>62.0</td>\n",
       "      <td>UDSKOE, RS</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>99999</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.5,134.4166666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31285099999</td>\n",
       "      <td>2024-01-01T03:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>54.5</td>\n",
       "      <td>134.416667</td>\n",
       "      <td>62.0</td>\n",
       "      <td>UDSKOE, RS</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>99999</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.5,134.4166666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31285099999</td>\n",
       "      <td>2024-01-01T06:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>54.5</td>\n",
       "      <td>134.416667</td>\n",
       "      <td>62.0</td>\n",
       "      <td>UDSKOE, RS</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>99999</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.5,134.4166666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31285099999</td>\n",
       "      <td>2024-01-01T09:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>54.5</td>\n",
       "      <td>134.416667</td>\n",
       "      <td>62.0</td>\n",
       "      <td>UDSKOE, RS</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>99999</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.5,134.4166666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31285099999</td>\n",
       "      <td>2024-01-01T12:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>54.5</td>\n",
       "      <td>134.416667</td>\n",
       "      <td>62.0</td>\n",
       "      <td>UDSKOE, RS</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>99999</td>\n",
       "      <td>V020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.5,134.4166666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION                 DATE SOURCE  LATITUDE   LONGITUDE  ELEVATION  \\\n",
       "0  31285099999  2024-01-01T00:00:00      4      54.5  134.416667       62.0   \n",
       "1  31285099999  2024-01-01T03:00:00      4      54.5  134.416667       62.0   \n",
       "2  31285099999  2024-01-01T06:00:00      4      54.5  134.416667       62.0   \n",
       "3  31285099999  2024-01-01T09:00:00      4      54.5  134.416667       62.0   \n",
       "4  31285099999  2024-01-01T12:00:00      4      54.5  134.416667       62.0   \n",
       "\n",
       "         NAME REPORT_TYPE CALL_SIGN QUALITY_CONTROL  ...  CU3  CV1  CV2  CV3  \\\n",
       "0  UDSKOE, RS       FM-12     99999            V020  ...  NaN  NaN  NaN  NaN   \n",
       "1  UDSKOE, RS       FM-12     99999            V020  ...  NaN  NaN  NaN  NaN   \n",
       "2  UDSKOE, RS       FM-12     99999            V020  ...  NaN  NaN  NaN  NaN   \n",
       "3  UDSKOE, RS       FM-12     99999            V020  ...  NaN  NaN  NaN  NaN   \n",
       "4  UDSKOE, RS       FM-12     99999            V020  ...  NaN  NaN  NaN  NaN   \n",
       "\n",
       "   CW1  GH1  IB2  KF1  OB1       COORDINATES  \n",
       "0  NaN  NaN  NaN  NaN  NaN  54.5,134.4166666  \n",
       "1  NaN  NaN  NaN  NaN  NaN  54.5,134.4166666  \n",
       "2  NaN  NaN  NaN  NaN  NaN  54.5,134.4166666  \n",
       "3  NaN  NaN  NaN  NaN  NaN  54.5,134.4166666  \n",
       "4  NaN  NaN  NaN  NaN  NaN  54.5,134.4166666  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column \"Coordinates\", which is \"Latitude, Longitude\"\n",
    "noaa['COORDINATES'] = noaa['LATITUDE'].astype('str') + ',' + noaa['LONGITUDE'].astype('str')\n",
    "noaa.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
