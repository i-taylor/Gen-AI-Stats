{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1698b99",
   "metadata": {},
   "source": [
    "# Lab 2: Data Wrangling, Analysis, and Visualization\n",
    "\n",
    "## Introduction\n",
    "In this assignment, you will delve into the essential steps of data preprocessing, wrangling, analysis, and visualization. These are crucial techniques in data science to clean, prepare, analyze, and present data effectively. You will be working with three distinct datasets, each presenting unique challenges and learning opportunities.\n",
    "\n",
    "*Again, you are not required to write any code; just run the cells and observe the outputs, except for the 'Reflection Exercise' section at the end.*\n",
    "\n",
    "### Overview of the Lab Topics\n",
    "- **Data Wrangling**: Handling missing values, removing duplicates, converting data types, merging multiple CSV files, and creating new columns\n",
    "- **Data Analysis**: Performing descriptive statistics, correlation analysis, grouping and aggregation, and trend analysis.\n",
    "- **Data Visualization**: Creating various types of plots to visualize the data.\n",
    "\n",
    "This lab will take a while to go through, so don't be afraid to take breaks. And remember to use an AI-copilot as you are going through this to ask questions about bits of code that you don't understand.\n",
    "\n",
    "You can copy the code into your GenAI tool and ask questions like \"Are there other ways of doing this?\" \"Can you explain the pros and cons of using this option?\" \"Can you breakdown this code for me in detail?\"\n",
    "\n",
    "I encourage you to do this to make the most out of the lab! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65190617-4cb0-46cf-be12-61fc8fb06d0e",
   "metadata": {},
   "source": [
    "## 1. Data Wrangling\n",
    "\n",
    "Data wrangling includes preprocessing and cleaning steps that are critical in the data analysis pipeline. The quality of data directly impacts the quality of insights that can be derived from it. Preprocessing involves transforming raw data into a clean and usable format. Cleaning involves handling missing values, correcting errors, and preparing the data for analysis.\n",
    "\n",
    "### Handling Missing Values\n",
    "Missing values are common in datasets and can significantly affect the results of your analysis. Common strategies to handle missing values include:\n",
    "- **Removal**: Removing rows or columns with missing values.\n",
    "- **Imputation**: Filling missing values with a specific value such as the mean, median, or mode of the column.\n",
    "- **Prediction**: Using machine learning models to predict missing values based on other features.\n",
    "\n",
    "Let's start by importing the required libraries and loading the CSV file for `shopping_behavior` dataset in `Kaggle Ecommerce` and examining the data to identify errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c14ae3-e570-4a9f-b845-af29fa37927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os  # Module for interacting with the operating system\n",
    "import pandas as pd  # Library for data manipulation and analysis\n",
    "import numpy as np  # Library for numerical computations\n",
    "\n",
    "# Define the relative path to the dataset CSV file\n",
    "file_path = '../Datasets/Kaggle_Ecommerce/shopping_behavior.csv'\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "shop_behav = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "shop_behav.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e3fdb0-48ce-4999-9406-d3442ccd0b94",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "Identify and handle missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bc2e7a-95ce-44bf-8d94-0cc751091287",
   "metadata": {},
   "source": [
    "This code checks for missing values in the `shop_behav` DataFrame.\n",
    "\n",
    "- **shop_behav.isnull()**: Identifies all the null (missing) values in the DataFrame.\n",
    "- **sum()**: Counts the total number of missing values in each column.\n",
    "\n",
    "The result shows the number of missing values per column, helping us understand the extent of missing data in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73273b0e-a2f1-463c-8023-53a16727ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify missing values\n",
    "shop_behav.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c5fed8-956f-4462-bc4b-150da3e65da9",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 10px;\">\n",
    "\n",
    "ðŸ¤– \n",
    "<br>\n",
    "**Now that you know which columns have null values, ask Generative AI about various methods of handling this. Remember to ask about the pros and the cons of different options.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a12323b-86e4-489c-a551-322ce72c3764",
   "metadata": {},
   "source": [
    "This code handles missing values in the `shop_behav` DataFrame. Here, we are filling the missing values with the mean of the corresponding column.\n",
    "\n",
    "- **missing_cols**: Identifies columns with any missing values.\n",
    "- **for col in missing_cols**: Iterates through each column with missing values.\n",
    "    - **if shop_behav[col].dtype in [np.float64, np.int64]**: Checks if the column is numerical.\n",
    "    - **shop_behav[col].fillna(shop_behav[col].mean(), inplace=True)**: Fills missing values in numerical columns with the column mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db61676a-bf39-4df1-afb9-50245effb9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with missing values\n",
    "missing_cols = shop_behav.columns[shop_behav.isnull().any()]\n",
    "\n",
    "# Fill missing values in numerical columns with the mean value of those columns\n",
    "for col in missing_cols:\n",
    "    # Check if the column's data type is either float64 or int64 (i.e., a numerical column)\n",
    "    if shop_behav[col].dtype in [np.float64, np.int64]:\n",
    "        # Replace NaN values with the mean of the column\n",
    "        shop_behav[col].fillna(shop_behav[col].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d997335f-cfc2-4020-b502-d048adc1550d",
   "metadata": {},
   "source": [
    "We again check for missing values, and as can be seen, there are none left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a3622c-640c-40e2-94d8-398fd2481b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rechecking for missing values\n",
    "shop_behav.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d381c2-ad94-44c9-9499-cdf098b1a024",
   "metadata": {},
   "source": [
    "### Removing Duplicates\n",
    "Duplicate records can skew your analysis and lead to incorrect insights. Removing duplicates ensures that each record in your dataset is unique. This is typically done by identifying and removing rows that have identical values across all columns.\n",
    "\n",
    "This code checks for duplicate rows in the `shov_behav` DataFrame.\n",
    "\n",
    "- **data2.duplicated()**: Identifies duplicate rows.\n",
    "- **sum()**: Counts the total number of duplicate rows in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e813005-dd64-4ea7-b404-95d4bd079227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify duplicates\n",
    "shop_behav.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd652bd-8d98-4ade-901b-6ea42ed4d657",
   "metadata": {},
   "source": [
    "This indicates that the dataset has one duplicate row. We will fix it now.\n",
    "\n",
    "- **shop_behav.drop_duplicates(inplace=True)**: Removes duplicate rows from the DataFrame and updates `shop_behav` in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7002d9-f5f9-479e-964d-4d2022673128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "shop_behav.drop_duplicates(inplace=True)\n",
    "shop_behav.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf72bc9-c2a7-4946-b37d-759eee326a3f",
   "metadata": {},
   "source": [
    "The dataset now has `0` duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae4ba5-fc3b-4eff-9662-a04ef3677e5a",
   "metadata": {},
   "source": [
    "### Data Type Conversion\n",
    "Ensuring that each column has the correct data type is crucial for accurate analysis. In a DataFrame, each column must contain only one type of data. This is because DataFrames are like tables where each column needs to be uniform in type. For example:\n",
    "- Dates should be stored as date objects.\n",
    "- Numbers should be in numerical formats like integers or floats.\n",
    "- Categorical data should be stored as category types.\n",
    "Let's look at an example with the 'Review Rating' column. This column should contain numbers (floats), but due to some rows having extra text like ' stars', its data type is currently a string (object). Here's what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b6b1a1-b2ab-4b68-b16b-71766b587e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_behav['Review Rating'][55:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b835c3",
   "metadata": {},
   "source": [
    "### Steps to Correct Data Type Conversion\n",
    "\n",
    "1. **Try to Convert the Column to Float**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e50dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shop_behav['Review Rating'] = shop_behav['Review Rating'].astype('float')\n",
    "except ValueError as e:\n",
    "    print(f\"Error encountered: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07053e4",
   "metadata": {},
   "source": [
    "- This code tries to change 'Review Rating' to float type.\n",
    "- It fails because some values have ' stars', which can't be converted to a number.\n",
    "- The error message tells us there's a problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. **Find the Problematic Rows**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d13ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to check if a value can be converted to float\n",
    "def can_convert_to_float(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Apply the function to each value in 'Review Rating' and find problematic rows\n",
    "problematic_rows = shop_behav[~shop_behav['Review Rating'].apply(can_convert_to_float)]\n",
    "print(problematic_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b782763",
   "metadata": {},
   "source": [
    "- This code finds rows where 'Review Rating' has the text 'stars'.\n",
    "- Printing these rows helps us see where the issue is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3b7ad5",
   "metadata": {},
   "source": [
    "3. **Clean the 'Review Rating' Column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edc9888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ' stars' from 'Review Rating'\n",
    "shop_behav['Review Rating'] = shop_behav['Review Rating'].str.replace(' stars', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6497e51",
   "metadata": {},
   "source": [
    "- This line removes ' stars' from all values in the 'Review Rating' column.\n",
    "- Now the column should have only numbers as strings, ready to convert to float."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660e7ced-b5fe-4256-9300-17d15db9604f",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 10px;\">\n",
    "\n",
    "ðŸ¤– \n",
    "<br>\n",
    "**Ask Generative AI the ways you can format these kinds of strings**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ecb5e7",
   "metadata": {},
   "source": [
    "\n",
    "4. **Displaying Data Types**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d01cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_behav.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4676ff63",
   "metadata": {},
   "source": [
    "\n",
    "- Displays the data types of all columns in the `shop_behav` DataFrame to verify the conversion. We see that Rating is still an object, so we have to convert it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c5a07-0a3c-4631-8f18-af9d77344596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the 'Review Rating' column by removing the ' stars' string and converting to float\n",
    "shop_behav['Review Rating'] = shop_behav['Review Rating'].str.rstrip(' stars').astype('float') \n",
    "\n",
    "# Display data types of the columns\n",
    "shop_behav.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfb4628-72cf-431a-b7fd-814c8c8d1c25",
   "metadata": {},
   "source": [
    "Again checking the same rows of the column, we can see that the data type is now `float64`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b671eb-13a8-41e5-90a2-7ccd1a03b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_behav['Review Rating'][55:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be9ad07",
   "metadata": {},
   "source": [
    "### Merging CSV Files\n",
    "When working with large datasets, data may be split across multiple files. Merging these files into a single dataset is often necessary. This involves reading each file and concatenating them into one dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8643fba9-bb49-4ca9-b002-eb19315515e5",
   "metadata": {},
   "source": [
    "We first load the NOAA dataset and list the files it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933facce-31e5-4804-aac6-f84da087411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../Datasets/NOAA_Weather'  # Define the path to the folder containing the CSV files\n",
    "\n",
    "# List comprehension to find all files in the folder that end with '.csv'\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "print(csv_files)  # Print the list of CSV files to check which files were found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42577288-939e-4a0d-89fc-1a3bfe1b6788",
   "metadata": {},
   "source": [
    "We can see that it has three different CSV files, which are basically weather data recordings from three different stations. Let's suppose we want to perform an analysis for all three stations, it is much more efficient to concatenate all of them into one and then perform the required tasks.\n",
    "\n",
    "The below code concatenates multiple CSV files into a single DataFrame.\n",
    "\n",
    "- **pd.concat([...])**: Concatenates the list of DataFrames into a single DataFrame.\n",
    "- **[pd.read_csv(os.path.join(folder_path, file)) for file in csv_files]**: This list comprehension reads each CSV file in the `csv_files` list and returns a list of DataFrames.\n",
    "    - **os.path.join(folder_path, file)**: Constructs the full file path for each CSV file.\n",
    "    - **pd.read_csv(...)**: Reads the CSV file into a DataFrame.\n",
    "- **ignore_index=True**: Ensures that the resulting DataFrame has a new, continuous index.\n",
    "\n",
    "The result is a single DataFrame, `noaa`, containing the data from all the CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b1b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and concatenate all CSV files\n",
    "noaa = pd.concat([pd.read_csv(os.path.join(folder_path, file)) for file in csv_files], ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "noaa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8754c91",
   "metadata": {},
   "source": [
    "- `pd.concat([...])` combines multiple DataFrames into a single DataFrame.\n",
    "- `[pd.read_csv(os.path.join(folder_path, file)) for file in csv_files]` reads each CSV file into a DataFrame and creates a list of these DataFrames.\n",
    "- `ignore_index=True` reindexes the combined DataFrame to have a continuous index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f9702a-bd67-47a7-8db0-37dd6e627543",
   "metadata": {},
   "source": [
    "To verify that `noaa` indeed has all three stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91946a62-c9b4-49d8-ab1e-2c877617e028",
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa['STATION'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e646b9f2",
   "metadata": {},
   "source": [
    "### Creating New Columns\n",
    "Creating new columns from existing data can provide additional insights or make data analysis easier. This can involve operations like arithmetic transformations, conditional logic, or feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de315e-7842-4b32-a38c-0e9ed1e3d8c4",
   "metadata": {},
   "source": [
    "This code creates a new column 'COORDINATES' in the `noaa` DataFrame by concatenating the 'LATITUDE' and 'LONGITUDE' columns as strings.\n",
    "\n",
    "- **noaa['LATITUDE'].astype('str')**: Converts the 'LATITUDE' column to strings.\n",
    "- **noaa['LONGITUDE'].astype('str')**: Converts the 'LONGITUDE' column to strings.\n",
    "- **noaa['LATITUDE'].astype('str') + ',' + noaa['LONGITUDE'].astype('str')**: Concatenates the latitude and longitude values with a comma in between to form coordinate strings.\n",
    "- **noaa['COORDINATES']**: Assigns the resulting coordinate strings to a new column 'COORDINATES' in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f9bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column \"Coordinates\", which is \"Latitude, Longitude\"\n",
    "noaa['COORDINATES'] = noaa['LATITUDE'].astype('str') + ',' + noaa['LONGITUDE'].astype('str')\n",
    "noaa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23290b5",
   "metadata": {},
   "source": [
    "## 2. Data Analysis\n",
    "\n",
    "In this section, we will perform various data analysis tasks on the Yelp reviews dataset. This includes descriptive statistics, correlation analysis, grouping and aggregation, and trend analysis.\n",
    "\n",
    "Let's first load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3403c04f-0e97-48c7-81d6-ea563290e0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>7/7/2018 22:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
       "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>1/3/2012 15:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
       "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>2/5/2014 20:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>1/4/2015 0:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>1/14/2017 20:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n",
       "2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
       "3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      3       0      0     0   \n",
       "1      5       1      0     1   \n",
       "2      3       0      0     0   \n",
       "3      5       1      0     1   \n",
       "4      4       1      0     1   \n",
       "\n",
       "                                                text             date  \n",
       "0  If you decide to eat here, just be aware it is...   7/7/2018 22:09  \n",
       "1  I've taken a lot of spin classes over the year...   1/3/2012 15:28  \n",
       "2  Family diner. Had the buffet. Eclectic assortm...   2/5/2014 20:30  \n",
       "3  Wow!  Yummy, different,  delicious.   Our favo...    1/4/2015 0:01  \n",
       "4  Cute interior and owner (?) gave us tour of up...  1/14/2017 20:54  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import os  # Module for interacting with the operating system\n",
    "import pandas as pd  # Library for data manipulation and analysis\n",
    "import numpy as np  # Library for numerical computations\n",
    "\n",
    "file_path = '../Datasets/Yelp_Reviews/reviews.csv'  # Define the path to the CSV file\n",
    "\n",
    "reviews = pd.read_csv(file_path)  # Read the CSV file into a DataFrame\n",
    "\n",
    "reviews.head()  # Display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2074cd-6790-4ee5-8f9d-b6debf966724",
   "metadata": {},
   "source": [
    "### Summary statistics\n",
    "\n",
    "#### Distribution of Ratings\n",
    "We analyze the distribution of ratings in the Yelp reviews dataset. Understanding the distribution of ratings can provide insights into customer satisfaction and help identify patterns or trends in the feedback.\n",
    "\n",
    "- **rating_distribution = reviews['stars'].value_counts().sort_index()**:\n",
    "    - **reviews['stars']**: Select the 'stars' column from the DataFrame `reviews`, which contains the ratings given in the reviews.\n",
    "    - **value_counts()**: Counts the occurrence of each unique rating value, giving us the number of reviews for each rating.\n",
    "    - **sort_index()**: Sorts the counts by the rating values (index) in ascending order.\n",
    "\n",
    "- **rating_distribution**:\n",
    "    - This variable now holds a Series with the count of reviews for each rating, sorted by the rating values. It provides a clear view of how many reviews were given for each rating level (e.g., 1 star, 2 stars, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19062529-59f3-4613-8f2b-450b11057b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stars\n",
       "1    222\n",
       "2    148\n",
       "3    236\n",
       "4    474\n",
       "5    883\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of Ratings\n",
    "rating_distribution = reviews['stars'].value_counts().sort_index()  # Count the occurrences of each rating and sort by rating value\n",
    "\n",
    "rating_distribution  # Display the distribution of ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #00008B; padding: 10px; color: white; padding: 10px;\">\n",
    "\n",
    "Now you can try to do something on your own with GenAI!\n",
    "\n",
    "ðŸ¤– **Suggested prompt**\n",
    "<br>\n",
    "\n",
    "This is my data:\n",
    "\n",
    "`<data>`\n",
    "\n",
    "{paste data}\n",
    "\n",
    "`</data>`\n",
    "\n",
    "In my lesson, we ran this code:\n",
    "\n",
    "`rating_distribution = reviews['stars'].value_counts().sort_index()  # Count the occurrences of each rating and sort by rating value`\n",
    "\n",
    "Given my dataset, what are some other summary statistics I could look at?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste your AI-generated code here to give it a go:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd61d5f",
   "metadata": {},
   "source": [
    "### Statistical Analysis\n",
    "Below are some basic statistical analyses you can do on your dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8bd291-112a-4043-b223-e65b5273e71c",
   "metadata": {},
   "source": [
    "#### Correlation Analysis: Review Length vs Useful Votes\n",
    "Here we analyze the statistical correlation between the length of a review and the number of useful votes it receives. By examining this correlation, we can understand if there is a linear relationship between these two variables.\n",
    "\n",
    "1. Calculate Review Length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50be5b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'review_length' which is the length of each review in characters\n",
    "reviews['review_length'] = reviews['text'].apply(len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a12547",
   "metadata": {},
   "source": [
    "- **reviews['text']**: Selects the 'text' column from the DataFrame reviews, which contains the review texts.\n",
    "- **apply(len)**: Applies the len function to each review text, calculating the length of each review in terms of the number of characters.\n",
    "- **reviews['review_length']**: Creates a new column 'review_length' in the DataFrame reviews to store the length of each review.\n",
    "\n",
    "2. **Select Relevant Columns**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e5d23a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with the relevant columns for correlation analysis\n",
    "review_length_vs_useful = reviews[['review_length', 'useful']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fd11a9",
   "metadata": {},
   "source": [
    "- **reviews[['review_length', 'useful']]**: Selects the 'review_length' and 'useful' columns from the DataFrame `reviews` and creates a new DataFrame `review_length_vs_useful` containing these two columns.\n",
    "\n",
    "3. **Calculate and Display the Correlation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8400f8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               review_length    useful\n",
      "review_length       1.000000  0.280841\n",
      "useful              0.280841  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation between review length and useful votes\n",
    "correlation = review_length_vs_useful.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dca1d9",
   "metadata": {},
   "source": [
    "- **review_length_vs_useful.corr()**: Computes the pairwise correlation of columns in the DataFrame `review_length_vs_useful`.\n",
    "- **print(correlation)**: Displays the correlation matrix, showing the correlation coefficient between 'review_length' and 'useful'.\n",
    "\n",
    "The correlation coefficient will provide a measure of how strongly review length and useful votes are related. A coefficient close to 1 indicates a strong positive correlation, close to -1 indicates a strong negative correlation, and close to 0 indicates no correlation.\n",
    "\n",
    "Hereâ€™s the complete code for the correlation analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746a5c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               review_length    useful\n",
      "review_length       1.000000  0.280841\n",
      "useful              0.280841  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Calculate Review Length\n",
    "reviews['review_length'] = reviews['text'].apply(len)\n",
    "\n",
    "# Select Relevant Columns\n",
    "review_length_vs_useful = reviews[['review_length', 'useful']]\n",
    "\n",
    "# Calculate and Display the Correlation\n",
    "correlation = review_length_vs_useful.corr()\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8957e",
   "metadata": {},
   "source": [
    "#### Group Comparison: Average Star Ratings\n",
    "Here, we will analyze the star ratings of different businesses using Analysis of Variance (ANOVA). In this lab, we will guide you step by step through the process of renaming businesses, filtering data, and performing ANOVA to compare the ratings.\n",
    "\n",
    "##### Step 1: Load the Dataset\n",
    "\n",
    "First, we need to load the dataset containing business reviews. We already did this abov, but we can import some additional libraries for the statistical analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49051794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>7/7/2018 22:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
       "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>1/3/2012 15:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
       "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>2/5/2014 20:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>1/4/2015 0:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>1/14/2017 20:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n",
       "2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
       "3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      3       0      0     0   \n",
       "1      5       1      0     1   \n",
       "2      3       0      0     0   \n",
       "3      5       1      0     1   \n",
       "4      4       1      0     1   \n",
       "\n",
       "                                                text             date  \n",
       "0  If you decide to eat here, just be aware it is...   7/7/2018 22:09  \n",
       "1  I've taken a lot of spin classes over the year...   1/3/2012 15:28  \n",
       "2  Family diner. Had the buffet. Eclectic assortm...   2/5/2014 20:30  \n",
       "3  Wow!  Yummy, different,  delicious.   Our favo...    1/4/2015 0:01  \n",
       "4  Cute interior and owner (?) gave us tour of up...  1/14/2017 20:54  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd  # Pandas is used for data manipulation and analysis.\n",
    "from scipy.stats import f_oneway  # Scipy's f_oneway function is used to perform ANOVA.\n",
    "\n",
    "file_path = '../Datasets/Yelp_Reviews/reviews.csv'  # Define the path to the CSV file\n",
    "\n",
    "reviews = pd.read_csv(file_path)  # Read the CSV file into a DataFrame\n",
    "\n",
    "reviews.head()  # Display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a4997",
   "metadata": {},
   "source": [
    "\n",
    "- **Pandas (`pd`)**: A powerful data manipulation library in Python. It provides data structures and functions needed to manipulate structured data.\n",
    "- **SciPy (`f_oneway`)**: A Python library used for scientific and technical computing. Here, we use the `f_oneway` function from SciPy's stats module to perform ANOVA.\n",
    "\n",
    "##### Step 2: Identify Top 10 Businesses\n",
    "\n",
    "Next, we will identify the top 10 businesses based on the number of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb2919ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_id\n",
      "GBTPC53ZrG1ZBY3DT8Mbcw    17\n",
      "pSmOH4a3HNNpYM82J5ycLA    12\n",
      "PY9GRfzr4nTZeINf346QOw    11\n",
      "W4ZEKkva9HpAdZG88juwyQ    10\n",
      "Zi-F-YvyVOK0k5QD7lrLOg     9\n",
      "EtKSTHV5Qx_Q7Aur9o4kQQ     9\n",
      "Dv6RfXLYe1atjgz3Xf4GGw     8\n",
      "SZU9c8V2GuREDN5KgyHFJw     7\n",
      "9gObo5ltOMo6UgsaXaHPWA     7\n",
      "VRGYwKE_Z77frm5NwLvJhw     7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of reviews for each business and sort in descending order\n",
    "business_review_counts = reviews['business_id'].value_counts()\n",
    "top_businesses = business_review_counts.head(10)\n",
    "\n",
    "# Display the top 10 businesses\n",
    "print(top_businesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fca812",
   "metadata": {},
   "source": [
    "- **`value_counts()`**: A function that counts the unique values in a column.\n",
    "- **`head(10)`**: Selects the top 10 entries from the Series.\n",
    "\n",
    "##### Step 3: Rename Top 10 Businesses\n",
    "\n",
    "We will rename the top 10 businesses as \"Business 1\", \"Business 2\", etc., for easier analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "951f86c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id business_label\n",
      "0  GBTPC53ZrG1ZBY3DT8Mbcw     Business_A\n",
      "1  pSmOH4a3HNNpYM82J5ycLA     Business_B\n",
      "2  PY9GRfzr4nTZeINf346QOw     Business_C\n",
      "3  W4ZEKkva9HpAdZG88juwyQ     Business_D\n",
      "4  Zi-F-YvyVOK0k5QD7lrLOg     Business_E\n",
      "5  EtKSTHV5Qx_Q7Aur9o4kQQ     Business_F\n",
      "6  Dv6RfXLYe1atjgz3Xf4GGw     Business_G\n",
      "7  SZU9c8V2GuREDN5KgyHFJw     Business_H\n",
      "8  9gObo5ltOMo6UgsaXaHPWA     Business_I\n",
      "9  VRGYwKE_Z77frm5NwLvJhw     Business_J\n"
     ]
    }
   ],
   "source": [
    "# Rename the top 10 businesses as businesses A-J for alphabetical sorting\n",
    "business_labels = ['Business_A', 'Business_B', 'Business_C', 'Business_D', 'Business_E', 'Business_F', 'Business_G', 'Business_H', 'Business_I', 'Business_J']\n",
    "top_10_businesses = top_businesses.index[:10].tolist()\n",
    "business_mapping = {business_id: business_labels[i] for i, business_id in enumerate(top_10_businesses)}\n",
    "\n",
    "# Create a new column 'business_label' with the new business names\n",
    "reviews['business_label'] = reviews['business_id'].map(business_mapping)\n",
    "\n",
    "# Verify that the business labels have been correctly assigned by displaying the top 10 businesses\n",
    "top_10_renamed = reviews[reviews['business_id'].isin(top_10_businesses)][['business_id', 'business_label']].drop_duplicates()\n",
    "top_10_renamed = top_10_renamed.sort_values(by='business_label').reset_index(drop=True)\n",
    "print(top_10_renamed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaf261b",
   "metadata": {},
   "source": [
    "##### Step 4: Filter Data for Top 10 Businesses\n",
    "\n",
    "We will filter the dataset to include only reviews for the top 10 businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d20f85d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  review_id                 user_id             business_id  \\\n",
      "37   pHwbdway4yeI-dSSmZA7-Q  qEEk0PuoH1dVa619t8fgpw  PY9GRfzr4nTZeINf346QOw   \n",
      "44   jC-fGfx-YLqxVBcyTAd4Pw  EBa-0-6AKoy6jziNexDJtg  W4ZEKkva9HpAdZG88juwyQ   \n",
      "49   cvQXRFLCyr0S7EgFb4lZqw  ZGjgfSvjQK886kiTzLwfLQ  EtKSTHV5Qx_Q7Aur9o4kQQ   \n",
      "61   4zopEEPqfwm-c_FNpeHZYw  JYYYKt6TdVA4ng9lLcXt_g  SZU9c8V2GuREDN5KgyHFJw   \n",
      "71   aAcQibR3zWOvk4atbCM3SA  7P9w2PrP4ZcJyDFwch51Ig  Zi-F-YvyVOK0k5QD7lrLOg   \n",
      "81   7rCsR3SARVF3vXNiw_Csgg  mmdf_Fi-Hh_3uZN5zE164A  9gObo5ltOMo6UgsaXaHPWA   \n",
      "108  yyrMqY7sNp5gT7KJ1AaYWA  pitYOVSsF8R1gWG1G0qxsA  GBTPC53ZrG1ZBY3DT8Mbcw   \n",
      "113  3dVcGYz6GokuEytLrfG8bA  FEI0XkOrUHufSW_rfOTPAA  Dv6RfXLYe1atjgz3Xf4GGw   \n",
      "119  S4nZgOgiv9w8MOiaWTpwBQ  8fPlzYWo0j_nQrJMeyF0Fw  pSmOH4a3HNNpYM82J5ycLA   \n",
      "143  pJRn59F_lyNO1zT3TCVd0Q  TGgfqWnUaCf6DM7TLuNhDQ  pSmOH4a3HNNpYM82J5ycLA   \n",
      "\n",
      "     stars  useful  funny  cool  \\\n",
      "37       4       0      0     0   \n",
      "44       3       0      0     0   \n",
      "49       5       3      1     1   \n",
      "61       5       0      0     0   \n",
      "71       5       0      0     0   \n",
      "81       5       0      0     0   \n",
      "108      4       0      0     0   \n",
      "113      4       1      0     0   \n",
      "119      5       0      0     0   \n",
      "143      3       0      0     0   \n",
      "\n",
      "                                                  text             date  \\\n",
      "37   We checked in around 2:30 pm.  Check-in was qu...  9/20/2017 16:16   \n",
      "44   In a word... \"OVERRATED!\".  The food took fore...  12/29/2013 2:37   \n",
      "49   On a scale of one to things that are awesome, ...  10/14/2009 1:15   \n",
      "61   We were a bit weary about trying the Shellfish...   5/31/2016 2:14   \n",
      "71   Definitely recommend for anyone looking for a ...  9/18/2016 17:05   \n",
      "81   My husband and I took my mother here for her 1...    9/6/2016 3:04   \n",
      "108  We have been here twice for brunch and have en...   3/7/2016 17:25   \n",
      "113  Good food, reasonably priced, and nice staff. ...  12/4/2012 23:58   \n",
      "119  I first heard about this place on the plane ri...   6/8/2015 21:11   \n",
      "143  This is a pretty good pancake place, but it's ...    3/4/2018 0:07   \n",
      "\n",
      "    business_label  \n",
      "37      Business_C  \n",
      "44      Business_D  \n",
      "49      Business_F  \n",
      "61      Business_H  \n",
      "71      Business_E  \n",
      "81      Business_I  \n",
      "108     Business_A  \n",
      "113     Business_G  \n",
      "119     Business_B  \n",
      "143     Business_B  \n"
     ]
    }
   ],
   "source": [
    "# Filter the dataset to include only the top 10 businesses\n",
    "top_10_reviews = reviews[reviews['business_label'].notnull()]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(top_10_reviews.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b7ab13",
   "metadata": {},
   "source": [
    "##### Step 5: Perform ANOVA\n",
    "\n",
    "Finally, we will perform ANOVA to compare the average star ratings of the top 10 businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "193d0b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 0.8336292812943005, p-value: 0.5871479728518842\n"
     ]
    }
   ],
   "source": [
    "# Perform ANOVA on the star ratings of the top 10 businesses\n",
    "groups = [top_10_reviews[top_10_reviews['business_label'] == f'Business_{letter}']['stars'] for letter in 'ABCDEFGHIJ']\n",
    "f_stat, p_value = f_oneway(*groups)\n",
    "\n",
    "# Display the ANOVA results\n",
    "print(f\"F-statistic: {f_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78810b4b",
   "metadata": {},
   "source": [
    "**Interpretation of Results:**\n",
    "\n",
    "- **F-statistic**: Indicates the ratio of variance between the group means to the variance within the groups.\n",
    "- **p-value**: If the p-value is less than 0.05, it suggests that there is a significant difference in the average star ratings among the businesses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a342cfb",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #00008B; padding: 10px; color: white; padding: 10px;\">\n",
    "\n",
    "Try to generate another kind of analysis here. \n",
    "\n",
    "ðŸ¤– **Suggested prompt**\n",
    "<br>\n",
    "\n",
    "This is my data:\n",
    "\n",
    "`<data>`\n",
    "\n",
    "{paste data}\n",
    "\n",
    "`</data>`\n",
    "\n",
    "In my lesson, we just performed a correlation analysis and an ANOVA. What are some other statistical analyses I could perform on my dataset? Please provide the pros and cons of each method and explain briefly how to implement them in Python.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e384e-877b-4e65-b831-98d057afb8c7",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "\n",
    "Thanks to GenAI tools, it's now possible for people without much experience to do analyses as advanced and specialized as Sentiment Analysis.\n",
    "\n",
    "Sentiment analysis is the process of using natural language processing (NLP) and machine learning techniques to determine the emotional tone or sentiment expressed in a piece of text. It is widely used in areas such as social media monitoring, customer feedback analysis, and market research to understand the opinions and feelings of individuals.\n",
    "\n",
    "And to get code for doing this, you could ask AI something like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd36b7e-b776-4776-96b9-3ab8a24e48d6",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #00008B; padding: 10px; color: white; padding: 10px;\">\n",
    "\n",
    "ðŸ¤–  **Suggested prompt:**\n",
    "\n",
    "<br>\n",
    "How can I perform sentiment analysis on my dataset of customer reviews in Python? Provide a Python code example that classifies the sentiment of each review as positive, negative, or neutral and calculates the distribution of these sentiments.\n",
    "\n",
    "Here's a sample of my dataset\n",
    "\n",
    "`<data>`\n",
    "\n",
    "`{paste data}`\n",
    "\n",
    "`</data>`\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8663f2af-2448-4874-85e5-022d09b4eb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Positive    1731\n",
       "Negative     224\n",
       "Neutral        8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install the necessary libraries\n",
    "# %pip install pandas textblob\n",
    "\n",
    "import pandas as pd  # Import the pandas library for data manipulation and analysis\n",
    "from textblob import TextBlob  # Import the TextBlob library for sentiment analysis\n",
    "\n",
    "# Function to classify sentiment\n",
    "def classify_sentiment(text):\n",
    "    \"\"\"\n",
    "    This function takes a text string as input and uses TextBlob to analyze its sentiment.\n",
    "    It returns 'Positive' if the polarity is greater than 0,\n",
    "    'Negative' if the polarity is less than 0, and 'Neutral' if the polarity is 0.\n",
    "    \"\"\"\n",
    "    analysis = TextBlob(text)  # Create a TextBlob object to analyze the sentiment of the text\n",
    "    if analysis.sentiment.polarity > 0:  # Check if the polarity is greater than 0\n",
    "        return 'Positive'  # Return 'Positive' for positive sentiment\n",
    "    elif analysis.sentiment.polarity < 0:  # Check if the polarity is less than 0\n",
    "        return 'Negative'  # Return 'Negative' for negative sentiment\n",
    "    else:\n",
    "        return 'Neutral'  # Return 'Neutral' for neutral sentiment\n",
    "\n",
    "# Apply sentiment analysis to the 'text' column of the reviews DataFrame\n",
    "reviews['sentiment'] = reviews['text'].apply(classify_sentiment)\n",
    "# This line applies the classify_sentiment function to each element in the 'text' column\n",
    "# and stores the result in a new column called 'sentiment'.\n",
    "\n",
    "# Calculate the distribution of sentiment values\n",
    "sentiment_distribution = reviews['sentiment'].value_counts()\n",
    "# This line counts the occurrences of each sentiment category\n",
    "# (Positive, Negative, Neutral) and stores the result in sentiment_distribution.\n",
    "\n",
    "# Display the sentiment distribution\n",
    "sentiment_distribution\n",
    "# This line prints the distribution of sentiments to the output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e3708d-a2d4-4065-91cf-8799c74ca985",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 10px;\">\n",
    "\n",
    "ðŸ¤– \n",
    "<br>\n",
    "**There are many more types of analysis that can be done on this dataset, it's all just a matter of which questions you want answered! For example- you might want to do sentiment analysis over time, i.e., analyze how the sentiment of reviews has changed over time to identify trends or shifts in customer satisfaction.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c098ce",
   "metadata": {},
   "source": [
    "## 3. Data Visualization\n",
    "\n",
    "In this section, we will create various plots to visualize the data and the results of our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8906f45d-5236-4d29-9fed-1750c57ba05d",
   "metadata": {},
   "source": [
    "### Bar Chart for Distribution of Ratings\n",
    "on\n",
    "This plot is a bar chart that visualizes the distribution of star ratings in the Yelp reviews dataset. It shows how frequently each star rating (1 to 5 stars) is given, providing insights into overall customer satisfactiotion\n",
    "\n",
    "- **import matplotlib.pyplot as plt**:\n",
    "    - Imports the `matplotlib.pyplot` module, which is used for creating visualizations.\n",
    "\n",
    "- **plt.figure(figsize=(10, 6))**:\n",
    "    - Creates a new figure with a specified size of 10 inches in width and 6 inches in height.\n",
    "\n",
    "- **reviews['stars'].value_counts().sort_index().plot(kind='bar')**:\n",
    "    - **reviews['stars']**: Selects the 'stars' column from the DataFrame `reviews`.\n",
    "    - **value_counts()**: Counts the occurrence of each unique rating value.\n",
    "    - **sort_index()**: Sorts the counts by the rating values in ascending order.\n",
    "    - **plot(kind='bar')**: Creates a bar plot of the sorted rating counts.\n",
    "\n",
    "- **plt.xlabel('Star Ratings')**:\n",
    "    - Sets the label for the x-axis to 'Star Ratings'.\n",
    "\n",
    "- **plt.ylabel('Frequency')**:\n",
    "    - Sets the label for the y-axis to 'Frequency'.\n",
    "\n",
    "- **plt.title('Distribution of Star Ratings')**:\n",
    "    - Sets the title of the plot to 'Distribution of Star Ratings'.\n",
    "\n",
    "- **plt.show()**:\n",
    "   - Displays the bar chart.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715730d0-b4d4-4204-a952-809d24e00335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bar Chart for Distribution of Ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "reviews['stars'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.xlabel('Star Ratings')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Star Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f13cf8-4e87-4e42-afea-db7089fbcc2e",
   "metadata": {},
   "source": [
    "### Scatter Plot for Review Length vs Useful Votes\n",
    "\n",
    "This plot is a scatter plot that visualizes the relationship between the length of reviews and the number of useful votes they receive. Each point represents a review, with its position determined by the review's length and the number of useful votes. This helps in identifying any patterns or correlations between these two variables.\n",
    "\n",
    "- **plt.scatter(reviews['review_length'], reviews['useful'], alpha=0.5)**:\n",
    "    - **plt.scatter()**: Creates a scatter plot.\n",
    "    - **reviews['review_length']**: Specifies the x-axis data, which is the length of the reviews.\n",
    "    - **reviews['useful']**: Specifies the y-axis data, which is the number of useful votes.\n",
    "    - **alpha=0.5**: Sets the transparency level of the points to 0.5, making it easier to see overlapping points.\n",
    "\n",
    "- **plt.xlabel('Review Length')**:\n",
    "    - Sets the label for the x-axis to 'Review Length'.\n",
    "\n",
    "- **plt.ylabel('Number of Useful Votes')**:\n",
    "    - Sets the label for the y-axis to 'Number of Useful Votes'.\n",
    "\n",
    "- **plt.title('Review Length vs Useful Votes')**:\n",
    "    - Sets the title of the plot to 'Review Length vs Useful Votes'.\n",
    "\n",
    "- **plt.show()**:\n",
    "    - Displays the scatter plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1135a67e-0096-4bce-9fee-577ae7b31a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot for Review Length vs Useful Votes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(reviews['review_length'], reviews['useful'], alpha=0.5)\n",
    "plt.xlabel('Review Length')\n",
    "plt.ylabel('Number of Useful Votes')\n",
    "plt.title('Review Length vs Useful Votes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f490e7-d207-4220-b501-802f2cf9addc",
   "metadata": {},
   "source": [
    "### Line Chart for Average Ratings Over Time\n",
    "n\n",
    "This plot is a line chart that visualizes the average star rating of reviews over time. It shows how the average rating has changed monthly, allowing for the identification of trends and patterns in customer satisfaction over the observed perioheight.\n",
    "\n",
    "- **monthly_avg_rating.plot()**:\n",
    "    - Plots the `monthly_avg_rat from the Data Analysis sectioning` Series, which contains the average star rating for each month, as a line chart.\n",
    "\n",
    "- **plt.xlabel('Date')**:\n",
    "    - Sets the label for the x-axis to 'Date'.\n",
    "\n",
    "- **plt.ylabel('Average Star Rating')**:\n",
    "    - Sets the label for the y-axis to 'Average Star Rating'.\n",
    "\n",
    "- **plt.title('Average Star Rating Over Time')**:\n",
    "    - Sets the title of the plot to 'Average Stasplays the line chart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f4dbb-1bf0-44c6-bbe6-030455d4d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line Chart for Average Ratings Over Time\n",
    "plt.figure(figsize=(10, 6))\n",
    "monthly_avg_rating.plot()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Star Rating')\n",
    "plt.title('Average Star Rating Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5364c4-70fd-46cc-ae5e-620a61fce238",
   "metadata": {},
   "source": [
    "The breaks in the lines indicate that no data was available for these months."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cb2663-0401-4878-985e-2b69ca590d8c",
   "metadata": {},
   "source": [
    "### Pie Chart for Sentiment Distribution\n",
    "\n",
    "This plot is a pie chart that visualizes the distribution of sentiment classifications (Positive, Negative, Neutral) in the Yelp reviews dataset. It shows the proportion of each sentiment category, providing insights into the overall sentiment of the reviews.\n",
    "\n",
    "- **sentiment_counts = reviews['sentiment'].value_counts()**:\n",
    "    - Counts the occurrences of each sentiment category in the 'sentiment' column of the DataFrame `reviews`, which we created in the Data Analysis section.\n",
    "    - **sentiment_counts**: Stores the counts of each sentiment.\n",
    "\n",
    "- **plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=140)**:\n",
    "    - **plt.pie()**: Creates a pie chart.\n",
    "    - **sentiment_counts**: Provides the data for the pie chart (the counts of each sentiment).\n",
    "    - **labels=sentiment_counts.index**: Labels each slice of the pie chart with the sentiment categories.\n",
    "    - **autopct='%1.1f%%'**: Displays the percentage of each slice with one decimal place.\n",
    "    - **startangle=140**: Rotates the start of the pie chart to 140 degrees for better visual presentation.\n",
    "\n",
    "- **plt.title('Sentiment Distribution of Reviews')**:\n",
    "    - Sets the title of the plot to 'Sentiment Distribution of Reviews'.\n",
    "\n",
    "- **plt.show()**:\n",
    "    - Displays the pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff05370-3d31-4b05-a0f6-73e4747187a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie Chart for Sentiment Distribution\n",
    "# Count the occurrences of each sentiment\n",
    "sentiment_counts = reviews['sentiment'].value_counts()\n",
    "\n",
    "# Plot the pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Sentiment Distribution of Reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de95caf7-5ecd-469a-b453-86fb230ee179",
   "metadata": {},
   "source": [
    "### Heat Map for Numeric Columns\n",
    "\n",
    "This plot is a heat map that visualizes the correlation between numeric columns in the Yelp reviews dataset. The heat map shows the strength and direction of the relationships between pairs of variables, helping to identify patterns and potential dependencies.\n",
    "\n",
    "- **import seaborn as sns**:\n",
    "    - Imports the `seaborn` library, which is used for creating advanced visualizations.\n",
    "\n",
    "- **numeric_cols = ['stars', 'useful', 'funny', 'cool']**:\n",
    "    - Defines a list of numeric columns that will be included in the heat map.\n",
    "\n",
    "- **corr_matrix = df[numeric_cols].corr()**:\n",
    "    - Computes the correlation matrix for the selected numeric columns.\n",
    "    - **df[numeric_cols]**: Selects the specified numeric columns from the DataFrame `df`.\n",
    "    - **corr()**: Calculates the pairwise correlation coefficients between the columns.\n",
    "\n",
    "- **plt.figure(figsize=(10, 8))**:\n",
    "    - Creates a new figure with a specified size of 10 inches in width and 8 inches in height.\n",
    "\n",
    "- **sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')**:\n",
    "    - **sns.heatmap()**: Plots the heat map.\n",
    "    - **corr_matrix**: Provides the data for the heat map (the correlation matrix).\n",
    "    - **annot=True**: Displays the correlation coefficients on the heat map.\n",
    "    - **cmap='coolwarm'**: Uses the 'coolwarm' colormap for the heat map.\n",
    "    - **fmt='.2f'**: Formats the correlation coefficients to two decimal places.\n",
    "\n",
    "- **plt.title('Correlation Heatmap of Numeric Columns')**:\n",
    "    - Sets the title of the plot to 'Correlation Heatmap of Numeric Columns'.\n",
    "\n",
    "- **plt.show()**:\n",
    "    - Displays the heat map.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce50850-7178-4afb-9cb1-4da19e007245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Heat Map for Numeric Columns\n",
    "# Select numeric columns for the heat map\n",
    "numeric_cols = ['stars', 'useful', 'funny', 'cool']\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = reviews[numeric_cols].corr()\n",
    "\n",
    "# Plot the heat map\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap of Numeric Columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55d42f7-4a9f-4143-a8d1-3b184c05232d",
   "metadata": {},
   "source": [
    "## 4. Reflection Exercise\n",
    "\n",
    "In this section, you will reflect on your learning experience and answer the following questions. Please provide your answers when prompted by the code.\n",
    "\n",
    "### Questions:\n",
    "\n",
    "1. **What specific data analysis technique or concept did you find most beneficial for your field, and how do you plan to apply it in a practical scenario related to your work or interests?**\n",
    "2. **What was the most challenging aspect of the data analysis techniques you learned in this module, considering your background and experience? How did you overcome this challenge, and what resources or strategies did you find most helpful?**\n",
    "\n",
    "Run the following two cells and input your answers in the text boxes that show up. Don't forget to press `Return` once you are done typing. In case you made a mistake or want to re-enter your answer, just run the corresponding cell again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dc315a-e045-424d-9d96-e631c1e63650",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_insight = input(\"What specific data analysis technique or concept did you find most beneficial for your field, and how do you plan to apply it in a practical scenario related to your work or interests?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49261335-4cc7-4408-a49a-d755876d658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_reflection = input(\"What was the most challenging aspect of the data analysis techniques you learned in this module, considering your background and experience? How did you overcome this challenge, and what resources or strategies did you find most helpful?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c1364-a799-41ba-9412-e09ea856983b",
   "metadata": {},
   "source": [
    "Running the following cell is really important, as this will save the answers you gave above. In case you change your answers to any of the above questions, please be sure to run the following cell again, to save the updated answers.\n",
    "\n",
    "You needn't be too concerned with what this code is really doing, but the crux is it is doing some string operations to convert your answers to a prompt, and then save that to a `.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee63283a-d67f-4591-8eee-bb9dc423586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..\\Prompts\\Prompt.txt', 'r') as file:\n",
    "    prompt = file.read()\n",
    "\n",
    "prompt = prompt.replace('***', learning_insight, 1)\n",
    "prompt = prompt.replace('***', challenge_reflection, 1)\n",
    "\n",
    "with open('..\\Prompts\\Prompt.txt', 'w') as file:\n",
    "    file.write(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a32af18",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this assignment, you have learned how to build a complete data analysis pipeline:\n",
    "- Preprocess and clean data (handling missing values, removing duplicates, data type conversion).\n",
    "- Wrangle data (merging CSV files, creating new columns).\n",
    "- Perform data analysis (descriptive statistics, correlation analysis, grouping and aggregation, trend analysis, sentiment analysis).\n",
    "- Create data visualizations (bar plots, box plots, scatter plots, line plots, pie charts, heatmaps).\n",
    "\n",
    "These skills are crucial for effective data analysis and will help you in future assignments and real-world data science tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
