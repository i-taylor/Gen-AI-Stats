{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d466d0-2350-4d40-8908-e9960fdd158f",
   "metadata": {},
   "source": [
    "---\n",
    "jupytext:\n",
    "  formats: md:myst\n",
    "  text_representation:\n",
    "    extension: .md\n",
    "    format_name: myst\n",
    "kernelspec:\n",
    "  display_name: Python 3\n",
    "  language: python\n",
    "  name: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9450ecd8-b245-4840-a1ce-c68538d24db0",
   "metadata": {},
   "source": [
    "# AI-powered Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aab6e3-0150-4f6b-bd68-6f4696d13d20",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In this notebook, you'll follow a guided walkthrough of how GenAI can be leveraged in the data analysis process. By the end, you'll have an open sandbox where you can experiment in this Python environment with your own AI-generated code. Press `Shift` + `Enter` to easily move forward in the notebook!\n",
    "\n",
    "### Learning to Think Step-by-Step in Data Analysis\n",
    "\n",
    "The main thing I want you to learn is to tackle data analysis in a, well, analytical way, breaking down the data analysis process into a clear step-by-step process:\n",
    "\n",
    "1. **Contextualize:** Identify your context. What data are you working with? What's the general topic of what you're trying to do? This initial context is crucial for framing your analysis.\n",
    "\n",
    "2. **Set a Goal:** What is your general goal? What do you want to achieve with this data analysis? Having a clear objective is key.\n",
    "\n",
    "3. **Strategize:** With that goal in mind, what's a good strategy for getting there? What tools do you want to use? What approaches or methods? What order do you need to do things in? Planning your approach ensures better outcomes.\n",
    "\n",
    "4. **Implement:** A carefully articulated strategy should help you in this main process that implements your tools and methods. Many people skip to this step without doing the work beforehand!\n",
    "\n",
    "5. **Interact:** This is the iterative process of data analysis. You will need to interpret your results, troubleshoot if things aren't going your way, or iterate to get a more refined version of what you want.\n",
    "\n",
    "6. **Document:** Once you've got what you want, make sure you record—in detail—what you did to get there! This is important both for sharing data and for revisiting your analyses later yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5865a08-8ab1-467b-9165-b4379734ed4d",
   "metadata": {},
   "source": [
    "### The Role of AI in Data Analysis\n",
    "\n",
    "How you interact with AI in the context of data analysis will depend on the AI tools you're using, the data, and your experience, among other factors. A useful way to direct your interactions is to consider different roles that AI can take on in this process. These roles roughly correspond to a mode of interaction and your comfort and experience level with the specific data analysis process you want to engage in.\n",
    "\n",
    "| Role       | Mode       | Level       |\n",
    "|:----------:|:----------:|:-----------:|\n",
    "| Tutor      | Learning   | Novice      |\n",
    "| Co-pilot   | Exploring  | Intermediate|\n",
    "| Intern     | Producing  | Expert      |\n",
    "\n",
    "Take these levels with a grain of salt because you might be experienced or advanced in some areas of data analysis but want to engage with AI as a tutor to learn a new analysis or use a new package.\n",
    "\n",
    "In the walkthrough, you'll see tabs for these different roles/modes of engaging with AI at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1126aef1-25e2-4742-b5fc-a992293a05bf",
   "metadata": {},
   "source": [
    "We will be working with the datasets that we described in Lab 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48398902-5ec7-459e-bee4-e582d2bc9d4b",
   "metadata": {},
   "source": [
    "# Step 1: Contextualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63371aba-189d-4edd-b4bf-558872936f71",
   "metadata": {},
   "source": [
    "Let's assume that your starting point is a dataset you have received and want to explore: `../Datasets/NOAA_Weather/udskoe-russia.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a434bc9e-a58b-466e-a7af-8b6e0262f77c",
   "metadata": {},
   "source": [
    "## Set up your GenAI tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a563b348-2394-4743-a63d-b7165c0c39fc",
   "metadata": {},
   "source": [
    "It's important to set up whatever your tool is with the context of your dataset and what you'll be engaging in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a762cf-ee76-442f-ad8f-85a7fd9e8295",
   "metadata": {},
   "source": [
    "For the purposes of this lab, I will be using ChatGPT with the GPT-4 model (I prefer it over the GPT-4o model) with code interpreter. And the initializing prompts I'm working with for each mode will be:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5303eb-9aa5-4c0d-a93a-380f605a517e",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    "\n",
    ":::{tab-item} Tutor (Learning Mode)\n",
    ":sync: tab-tutor-contextualize\n",
    "```\n",
    "Act as a Data Analysis Tutor to provide a strong educational foundation for my data analysis project.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "1. Educate: Explain each step and decision clearly.\n",
    "2. Guide: Use the provided CSV file for illustrations and answering questions.\n",
    "3. Respond Patiently: Answer queries with clear, instructive insights, waiting for my cues.\n",
    "4. Review: Discuss errors or misconceptions post-evaluation.\n",
    "5. Confirm: Paraphrase my instructions to ensure alignment.\n",
    "\n",
    "Working Environment: Jupyter Notebook.\n",
    "\n",
    "Paraphrase my instructions to verify your comprehension.\n",
    "```\n",
    ":::\n",
    "\n",
    ":::{tab-item} Co-pilot (Exploring Mode)\n",
    ":sync: tab-copilot-contextualize\n",
    "```\n",
    "Serve as a Data Analysis Copilot to navigate my data analysis project.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "1. Collaborate: Understand data nuances influencing our analysis.\n",
    "2. Integrate: Use the provided CSV file in our workspace for discussions.\n",
    "3. Dialogue: Engage in a two-way interaction, pausing for my input.\n",
    "4. Review: Jointly assess results, considering improvements.\n",
    "5. Confirm: Echo my directives to ensure synchronization.\n",
    "\n",
    "Working Environment: Jupyter Notebook.\n",
    "\n",
    "Echo my objectives back to confirm alignment.\n",
    "\n",
    "```\n",
    ":::\n",
    "\n",
    ":::{tab-item} Intern (Producing Mode)\n",
    ":sync: tab-intern-contextualize\n",
    "```\n",
    "Function as a Data Analysis Intern, executing tasks I delegate.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "1. Query: Request details influencing task outcomes.\n",
    "2. Execute: Load and apply the provided CSV file as instructed.\n",
    "3. Conform: Follow instructions strictly, without introducing new steps.\n",
    "4. Feedback: Confirm if steps align with objectives post-execution.\n",
    "5. Repeat: Echo my instructions to demonstrate adherence.\n",
    "\n",
    "Working Environment: Jupyter Notebook.\n",
    "\n",
    "Retell my commands to confirm accurate following.\n",
    "```\n",
    ":::\n",
    "\n",
    "And, yes, these were generated and iterated with AI!\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f042e19-31c2-4cf0-a780-18d6cf9abb28",
   "metadata": {},
   "source": [
    ":::{attention} Prompts are not magic or universal\n",
    ":class: dropdown\n",
    "\n",
    "These suggested prompts are a _starting point_, but you'll have to actually put some thought into what makes sense for you to include in your prompt:\n",
    "- How big is your context window? (i.e. how much text can you put in there)\n",
    "- Does your tool have a tendency to give verbose (long, wordy) replies?\n",
    "- Can you access other settings like the systems prompt etc?\n",
    "\n",
    "**There are no magic words that will reliably get you a perfect result from an AI chatbot**. Even when you do find something close to a \"perfect prompt\", it may stop working after the model is updated or some other aspect of the tool's design is changed.\n",
    "\n",
    "Any of these will affect the best way to get the most use out of your AI tool. This isn't even covering the fact that many IDE's are now incorporating GenAI into their products, meaning you can often talk to GPT-4, Gemini and other AI model's directly from your notebook.\n",
    "\n",
    "Instead of focusing on optimizing for the current capabilities of the AI tools around you, focus on understanding the _way_ you can delegate and automate aspects of data analysis given the components of that process--i.e. the steps in this exercise!\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2b2750-d1f2-4039-8193-6d6174bd4b47",
   "metadata": {},
   "source": [
    "Depending on your tool of choice, you may note be able to refer to a CSV file or have it run code with that CSV file. Below are some suggested initializing prompts from our readings if you want ideas of what direction to go in for adapting your prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2984d-b21d-46b8-b8f3-82959f3c14b8",
   "metadata": {},
   "source": [
    "::::{note} Adapting context depending on tool\n",
    "\n",
    "Below are some example prompts from the Step 0: Context and Setup reading if you need a refresher of what to consider for tool-specific prompting.\n",
    "\n",
    ":::{seealso} Basic (no code interpreter or file upload)\n",
    ":class: dropdown\n",
    "\n",
    "Start the conversation off by specifying your situation and what you’ll be trying to do. I like to prompt with a role I want the GenAI bot to take on.\n",
    "\n",
    "An example of what that initial prompt might look like if you can't upload your data:\n",
    "\n",
    "```\n",
    "Role: Act as a Data Analysis Copilot, providing advice and educational explanations on how to approach my data analysis project.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "Inquire and Clarify: Ask about details that can impact your advice (e.g., data types, dataframe or variable attributes).\n",
    "\n",
    "Contextual Understanding: Use the provided pasted data as context for answering my questions.\n",
    "\n",
    "Here is the data:\n",
    "<data>\n",
    "{paste in some data here,\n",
    "depending on context window,\n",
    "it may only be a few lines}\n",
    "</data>\n",
    "\n",
    "Direct Responses: Answer my questions directly and do not proceed with additional steps until I explicitly ask.\n",
    "\n",
    "Concise and Educational Explanations: Provide concise explanations, discuss the general consensus on different options, and give clear recommendations on how I should proceed, explaining the reasoning behind your advice.\n",
    "\n",
    "Verification Guidance: Provide instructions on how I can verify that the code works and achieves the intended goal.\n",
    "\n",
    "Working Environment: I am using a Jupyter notebook for my work.\n",
    "\n",
    "Repeat back the instructions I have given to ensure understanding.\n",
    "```\n",
    "The last sentence is mainly so that you can separate your first actual query from this role setting stage, and it should give you an idea of how the model is interpreting your instructions. \n",
    "\n",
    "The details of this are beyond the scope of this short course, but you can think of it this way: your input determines your output, and priming the conversation by giving context will influence the output.\n",
    "\n",
    "Feel free to copy this template and adjust as needed.\n",
    "\n",
    ":::\n",
    "\n",
    ":::{seealso} File upload (no code interpreter)\n",
    ":class: dropdown\n",
    "Same as above but you can just say you attached the file instead of pasting it in, you can reference it as an attached file.\n",
    "\n",
    "\n",
    "```\n",
    "Role: Act as a Data Analysis Copilot providing advice and educational explanations on how to approach my data analysis project.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "1. Inquire and Clarify: Ask about details that can impact your advice (e.g., data types, dataframe or variable attributes).\n",
    "    \n",
    "2. Contextual Understanding: Load and use the attached spreadsheet (CSV file) as context for answering my questions.\n",
    "    \n",
    "3. Direct Responses: Answer my questions directly and do not proceed with additional steps until I explicitly ask.\n",
    "    \n",
    "4. Concise and Educational Explanations: Provide concise explanations, discuss the general consensus on different options, and give clear recommendations on how I should proceed, explaining the reasoning behind your advice.\n",
    "    \n",
    "5. Verification Guidance: Provide instructions on how I can verify that the code works and achieves the intended goal.\n",
    "    \n",
    "\n",
    "Working Environment: I am using a Jupyter notebook for my work.\n",
    "\n",
    "Repeat back the instructions I have given to ensure understanding.\n",
    "```\n",
    ":::\n",
    "\n",
    ":::{seealso} Code interpreter\n",
    ":class: dropdown\n",
    "This is in some ways the easiest option because you can have it generate and run code for you to do all the work. However, you’ll still need to ask questions to make sure it has done the task correctly. Some of this can be alleviated by priming it to reflect on its answers at the beginning of the conversation with something like: “After running code, revisit my question, critically evaluate your approach, and verify if the output achieved the goal.”\n",
    "\n",
    "Here’s what the complete first prompt could look like:\n",
    "\n",
    "```\n",
    "Role: Act as a Data Analysis Copilot providing advice and educational explanations on how to approach my data analysis project.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "1. Inquire and Clarify: Ask about details that can impact your advice (e.g., data types, dataframe or variable attributes).\n",
    "    \n",
    "2. Contextual Understanding: Load and use the attached CSV file as context for answering my questions.\n",
    "    \n",
    "3. Direct Responses: Answer my questions directly and do not proceed with additional steps until I explicitly ask.\n",
    "    \n",
    "4. Critical Evaluation: After running code, revisit my question, critically evaluate your approach, and verify if the output achieved the goal.\n",
    "    \n",
    "5. Instruction Reiteration: Repeat back the instructions I have given to ensure understanding.\n",
    "    \n",
    "\n",
    "Working Environment: I am using a Jupyter notebook for my work.\n",
    "\n",
    "Repeat back the instructions I have given to ensure understanding.\n",
    "```\n",
    ":::\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebc1587-2fe3-46ef-85de-f4dba0ab36df",
   "metadata": {},
   "source": [
    "## Understand what you're working with\n",
    "\n",
    "\n",
    "This is a stage in data analysis where the a user's level really makes a difference in how useful AI can be. All groups can leverage GenAI tools for some combinaton of intformation retrieval and soundboarding. Even an expert could benefit from this if they're familiar with the subject matter or the types of analysis that are done in a particular field, but maybe they don't know the specific dataset, or at the very least it can help them organize their thoughts.\n",
    "\n",
    "::::{tab-set}\n",
    "\n",
    ":::{tab-item} Tutor (Learning Mode)\n",
    ":sync: tab-tutor-contextualize\n",
    "\n",
    "Depending on how unfamiliar you are with the general subject matter and the dataset, you may want to start off very broadly with asking what fields interact and analyze this kind of data, what it is about, what you can learn from it etc. You can ask about how it's formatted and what that means.\n",
    "\n",
    "Example prompt:\n",
    "> I don't know anything about the type of data I'm working with here. Can you tell me more about the subject matter and what is represented in the file?\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Co-pilot (Exploring Mode)\n",
    ":sync: tab-copilot-contextualize\n",
    "\n",
    "You may know a little bit about the data. Maybe you've worked with similar things before and you want to think more creatively. You can use AI to engage in some soundboarding about what is typically done vs. what is cutting edge or what could be an innovative approach.\n",
    "\n",
    "Example prompt: \n",
    "> What kinds of analyses are usually done with this data? And what could be an interesting novel way to look at it?\n",
    "\n",
    ":::\n",
    "\n",
    ":::{tab-item} Intern (Producing Mode)\n",
    ":sync: tab-intern-contextualize\n",
    "\n",
    "If you're familiar with the type, format, and field of the data, as well as the kinds of analyses that are usually done, this could be a good time to state, for the AI \n",
    ":::\n",
    "\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9832e355-44d3-434d-ae2b-0a551b7183ef",
   "metadata": {},
   "source": [
    "::::{tab-set}\n",
    "\n",
    ":::{tab-item} Tutor (Learning Mode)\n",
    ":sync: tab-tutor-contextualize\n",
    "- AI suggests key readings on your data's subject area.\n",
    "- AI outlines common questions to consider for understanding the context.\n",
    ":::\n",
    "\n",
    ":::{tab-item} Co-pilot (Exploring Mode)\n",
    ":sync: tab-copilot-contextualize\n",
    "- AI helps refine search queries for literature and data sources.\n",
    "- AI analyzes metadata to give an overview of the data structure.\n",
    ":::\n",
    "\n",
    ":::{tab-item} Intern (Producing Mode)\n",
    ":sync: tab-intern-contextualize\n",
    "- AI drafts a context summary based on inputs about the problem domain.\n",
    "- AI pre-processes data for preliminary overview (e.g., missing values, data types).\n",
    ":::\n",
    "\n",
    "::::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57fcb84-67c8-43e0-8697-58052113a3a9",
   "metadata": {},
   "source": [
    "In this notebook, you'll encounter specific indicators to prompt your actions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec369b83-8850-4e3b-ab16-79547ef55ee1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "::::{note} **Use GenAI** \n",
    "This cue invites you to use GenAI for problem-solving. You can try your own prompt or use the provided example.\n",
    ":::{dropdown} Example Prompt\n",
    ":::{code-cell}\n",
    "This is where you’d find an example prompt you could paste into your GenAI tool of choice.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbcd131-0cbf-481d-abd5-d30179333477",
   "metadata": {},
   "source": [
    ":::{warning} **Show AI-Solution**\n",
    ":class: dropdown\n",
    "If, for any reason, you cannot use a GenAI chatbot, you have the option to refer to a solution generated with our example prompt. However, to maximize learning, we encourage you to generate and apply your own solutions, as the course aims to develop your independent use of AI tools.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c87461-ba89-473e-bb7b-92eeabbbe381",
   "metadata": {},
   "source": [
    ":::{tip} **AI-Sandbox**\n",
    "There will be blocks like this, showing you a code block where you can paste and execute your own AI-generated code. These blocks usually follow guided instructions on the prompts you want to use and the problem you are solving.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dfcde2-e340-4ff2-a17f-62fc1582a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# They will be followed by an editable code block like this. You can enter your code from the next line!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e855c-e2f0-4c63-af35-c229ab4198ae",
   "metadata": {},
   "source": [
    "You’ve been given a CSV file and are tasked with cleaning the data. While there may be some glaring issues that you can see if you open the file in a spreadsheet editor (like Excel), that’s not always a feasible approach. Sometimes there’s too much data to go through everything manually and sometimes the problems are subtle and can easily be missed by a human observer (human-error is often the reason the issue was there in the first place). \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8560e9f1-64ed-4ec8-84f0-9aa51c4f71f3",
   "metadata": {},
   "source": [
    "Let's start by importing the required libraries and loading the CSV file for `shopping_behavior`  dataset in the `Kaggle Ecommerce` and examining the data to identify errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07468512-8c28-47b7-8311-7d9c311cd193",
   "metadata": {},
   "source": [
    "First we load the necessary libraries (i.e. the prewritten code from packages). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad527a68-f918-43b0-ad0f-fb74e2d8a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "from pathlib import Path  # Module for handling file paths\n",
    "import pandas as pd  # Library for data manipulation and analysis\n",
    "import numpy as np  # Library for numerical computations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3507db10-9a11-4469-ad39-f063321c1376",
   "metadata": {},
   "source": [
    "These have already been installed here, but if you were to run these locally without having them, you’d get an error and need to install them first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bfb5fa-14fc-43bf-b48b-8890fdb934ab",
   "metadata": {},
   "source": [
    "Then we can read in our CSV file as a DataFrame so we can use it in our Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918cf636-67cd-4da7-a82e-054b9804ffa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Item Purchased</th>\n",
       "      <th>Category</th>\n",
       "      <th>Purchase Amount (USD)</th>\n",
       "      <th>Location</th>\n",
       "      <th>Size</th>\n",
       "      <th>Color</th>\n",
       "      <th>Season</th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Subscription Status</th>\n",
       "      <th>Shipping Type</th>\n",
       "      <th>Discount Applied</th>\n",
       "      <th>Promo Code Used</th>\n",
       "      <th>Previous Purchases</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Frequency of Purchases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>Male</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>53</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>L</td>\n",
       "      <td>Gray</td>\n",
       "      <td>Winter</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Express</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>14</td>\n",
       "      <td>Venmo</td>\n",
       "      <td>Fortnightly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>Male</td>\n",
       "      <td>Sweater</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>64</td>\n",
       "      <td>Maine</td>\n",
       "      <td>L</td>\n",
       "      <td>Maroon</td>\n",
       "      <td>Winter</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Express</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Fortnightly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>Male</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>73</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>S</td>\n",
       "      <td>Maroon</td>\n",
       "      <td>Spring</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Free Shipping</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>23</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Weekly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>Male</td>\n",
       "      <td>Sandals</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>90</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>M</td>\n",
       "      <td>Maroon</td>\n",
       "      <td>Spring</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Next Day Air</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>49</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>Weekly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>49</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>M</td>\n",
       "      <td>Turquoise</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2.7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Free Shipping</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>31</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>Annually</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer ID  Age Gender Item Purchased  Category Purchase Amount (USD)  \\\n",
       "0            1   55   Male         Blouse  Clothing                    53   \n",
       "1            2   19   Male        Sweater  Clothing                    64   \n",
       "2            3   50   Male          Jeans  Clothing                    73   \n",
       "3            4   21   Male        Sandals  Footwear                    90   \n",
       "4            5   45   Male         Blouse  Clothing                    49   \n",
       "\n",
       "        Location Size      Color  Season Review Rating Subscription Status  \\\n",
       "0       Kentucky    L       Gray  Winter           3.1                 Yes   \n",
       "1          Maine    L     Maroon  Winter           3.1                 Yes   \n",
       "2  Massachusetts    S     Maroon  Spring           3.1                 Yes   \n",
       "3   Rhode Island    M     Maroon  Spring           3.5                 Yes   \n",
       "4         Oregon    M  Turquoise  Spring           2.7                 Yes   \n",
       "\n",
       "   Shipping Type Discount Applied Promo Code Used  Previous Purchases  \\\n",
       "0        Express              Yes             Yes                  14   \n",
       "1        Express              Yes             Yes                   2   \n",
       "2  Free Shipping              Yes             Yes                  23   \n",
       "3   Next Day Air              Yes             Yes                  49   \n",
       "4  Free Shipping              Yes             Yes                  31   \n",
       "\n",
       "  Payment Method Frequency of Purchases  \n",
       "0          Venmo            Fortnightly  \n",
       "1           Cash            Fortnightly  \n",
       "2    Credit Card                 Weekly  \n",
       "3         PayPal                 Weekly  \n",
       "4         PayPal               Annually  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the relative path to the dataset CSV file\n",
    "file_path = Path(\"..\") / \"Datasets\" / \"Kaggle_Ecommerce\" / \"shopping_behavior.csv\"\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "shop_behav = pd.read_csv(file_path)\n",
    "# Display the first 5 rows of the DataFrame\n",
    "shop_behav.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d07a030-f89f-417f-af6a-e41d36713354",
   "metadata": {},
   "source": [
    "## 1. Understanding the issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d28c55-3704-4628-9c35-2022c6c0d32e",
   "metadata": {},
   "source": [
    "### A General Checklist for Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d17f3a-7fcf-4b57-a5fa-dee462923a29",
   "metadata": {},
   "source": [
    "It's often useful to go through some basic quality control by going through a checklist of common issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96a58e3-1c7d-4418-b8cf-c806139c879d",
   "metadata": {},
   "source": [
    ":::{note} **Use GenAI** to get a data wrangling checklist\n",
    "Use GenAI as an educational tool to learn about common data cleaning issues you might face so that you can make a checklist of our possible issues.\n",
    "\n",
    "Think of a prompt that might give you a good overview of common data cleaning issues.\n",
    "\n",
    ":::{dropdown} Example Prompt\n",
    ":::{code-cell}\n",
    "What are common data cleaning issues I should look out for when preparing a dataset for analysis?\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d6bb64-cbb3-4dfb-bcbe-aff1f5f4b76a",
   "metadata": {},
   "source": [
    ":::{warning} Show AI-Solution\r\n",
    ":class: dropdown\r\n",
    "\r\n",
    "Data cleaning is crucial to ensure the integrity of your analysis. Here are some common issues to watch out for:\r\n",
    "\r\n",
    "1. **Missing Values**: Incomplete datasets can lead to biased or incorrect results. You’ll need to decide whether to impute missing values, remove the affected rows, or even ignore them, depending on the situation and the proportion of missing data.\r\n",
    "   \r\n",
    "2. **Duplicate Data**: Redundant entries can skew your analysis, leading to overestimated significance or effects. Identifying and removing duplicates is essential, especially in datasets where entries should be unique.\r\n",
    "   \r\n",
    "3. **Inconsistent Formats**: Data collected from different sources or methods might have varying formats. For instance, dates might be recorded as DD-MM-YYYY in one part and MM-DD-YYYY in another. Standardizing these into a single format is necessary for accurate analysis.\r\n",
    "   \r\n",
    "4. **Outliers and Anomalies**: Extreme values can significantly affect the results of your analysis. Determining whether outliers are due to data entry errors, measurement errors, or genuine extreme variations is important. Sometimes, outliers are insightful; other times, they are just noise.\r\n",
    "   \r\n",
    "5. **Incorrect Data Types**: Numerical values recorded as strings, categorical data treated as continuous, etc., can mess up data processing. Converting data to appropriate types is crucial.\r\n",
    "   \r\n",
    "6. **Typos and Spelling Errors**: Errors in categorical data can create artificially inflated categories. For example, 'Brown' vs. 'Borwn' in color categories. These need to be corrected through spelling checks or manual review.\r\n",
    "   \r\n",
    "7. **Scale and Unit Inconsistencies**: Ensure all data points are measured on the same scale and units (e.g., kilograms vs. pounds, or meters vs. feet) to maintain consistency across the dataset.\r\n",
    "   \r\n",
    "8. **Encoding Issues**: Problems with character encoding can lead to strange characters appearing in your dataset, especially if the data comes from multiple international sources.\r\n",
    "   \r\n",
    "9. **Irrelevant or Redundant Features**: Not all features in your dataset may be relevant to your analysis. Identifying and removing irrelevant or redundant features can simplify your model and improve performance.\r\n",
    "\r\n",
    "Addressing these issues thoroughly can enhance the quality of your analysis and help you draw more accurate conclusions from your data.\r\n",
    ":::\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3223142a-349e-4db6-8020-9a986f1f2501",
   "metadata": {},
   "source": [
    "### Tackling a specific issue: missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91876bb9-8377-4bc8-87da-0656d2597c62",
   "metadata": {},
   "source": [
    "Now that you have your list of general wrangling/cleaning issues to look out for, it’s time to address these issues. Not all of them will be relevant, but it’s a good idea to check for as many of them as you can. Since we made the dataset, we know what’s wrong with it so you can have the advantage of knowing which issues we’ll deal with!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f68ff-0f61-4089-96bc-4455efb718e0",
   "metadata": {},
   "source": [
    "Let’s walk through solving our first problem together and focus on missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce4167-3065-444c-b935-7e1d8f750008",
   "metadata": {},
   "source": [
    ":::{note} **Use GenAI** to understand how missing values are usually handled\n",
    "Use GenAI to figure out how to find and handle missing values. You can do this in multiple steps (i.e. ask how to identify missing data first, then how to handle it), but since this is a pretty straightforward issue, you can just ask both in one go.\n",
    ":::{dropdown} Example Prompt\n",
    ":::{code-cell}\n",
    "How can I identify and handle missing data in a Python DataFrame?\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbe1ce1-d8f4-4bbc-9f11-e4fa71badc96",
   "metadata": {},
   "source": [
    ":::{warning} Show AI-Solution\n",
    ":class: dropdown\n",
    "**Identifying and Handling Missing Data in a DataFrame**\n",
    "\n",
    "**Identifying Missing Data**\n",
    "\n",
    "To identify missing data in a DataFrame, we can use the `isnull()` or `isna()` method, which will return a DataFrame of the same shape, but with boolean values indicating the presence of missing data.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'A': [1, 2, None, 4],\n",
    "    'B': [None, 2, 3, 4],\n",
    "    'C': [1, 2, 3, None]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Identifying missing data\n",
    "missing_data = df.isnull()\n",
    "print(missing_data)\n",
    "```\n",
    "\n",
    "To get a summary of the missing data, we can use the `sum()` method along with `isnull()`.\n",
    "\n",
    "```python\n",
    "# Summary of missing data\n",
    "missing_summary = df.isnull().sum()\n",
    "print(missing_summary)\n",
    "```\n",
    "\n",
    "**Handling Missing Data**\n",
    "\n",
    "There are several strategies to handle missing data:\n",
    "\n",
    "**Removing Missing Data:**\n",
    "\n",
    "- **Remove rows with any missing values:**\n",
    "\n",
    "```python\n",
    "df_dropped_rows = df.dropna()\n",
    "print(df_dropped_rows)\n",
    "```\n",
    "\n",
    "- **Remove columns with any missing values:**\n",
    "\n",
    "```python\n",
    "df_dropped_columns = df.dropna(axis=1)\n",
    "print(df_dropped_columns)\n",
    "```\n",
    "\n",
    "**Filling Missing Data:**\n",
    "\n",
    "- **Fill missing values with a specific value:**\n",
    "\n",
    "```python\n",
    "df_filled_value = df.fillna(0)\n",
    "print(df_filled_value)\n",
    "```\n",
    "\n",
    "- **Fill missing values using forward fill (propagate last valid observation forward):**\n",
    "\n",
    "```python\n",
    "df_filled_forward = df.fillna(method='ffill')\n",
    "print(df_filled_forward)\n",
    "```\n",
    "\n",
    "- **Fill missing values using backward fill (propagate next valid observation backward):**\n",
    "\n",
    "```python\n",
    "df_filled_backward = df.fillna(method='bfill')\n",
    "print(df_filled_backward)\n",
    "```\n",
    "\n",
    "- **Fill missing values with the mean of the column:**\n",
    "\n",
    "```python\n",
    "df_filled_mean = df.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "print(df_filled_mean)\n",
    "```\n",
    "\n",
    "**Choosing the Right Method**\n",
    "\n",
    "The method you choose to handle missing data depends on the context of your analysis and the nature of the data. For example, if missing values are few and scattered, filling them with the mean might be a good choice. However, if a column has a large proportion of missing values, it might be better to drop that column.\n",
    "\n",
    "Always consider the impact of your chosen method on the integrity and validity of your analysis.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bdf9b2-8472-450d-84c4-6a47674a9bd3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "As you can see from the AI-output, you’ll usually get multiple suggestions on how you can solve the problem.\n",
    "\n",
    "In this case, your options are to leave it as is (which may not have come up as a suggestion!), drop columns or rows with missing values, or to fill missing values somehow (there are multiple ways to do this, ranging in complexity). \n",
    "\n",
    "Since AI is unlikely to question your request, it may be led astray by your question, so this is a great example of cases where you want to think about prompting it *critically*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f61ace8-7e60-4328-bc04-d2563e3660d1",
   "metadata": {},
   "source": [
    "## 2. Developing a strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e10288-aaf2-407c-8ea6-d011b0274e1a",
   "metadata": {},
   "source": [
    ":::{note} **Use GenAI** to decide how to handle missing values\n",
    "Use GenAI to help you make your decision about what to do. Think about how to prompt it so it doesn’t assume you know the right answer.\n",
    ":::{dropdown} Example Prompt\n",
    ":::{code-cell}\n",
    "I've noticed missing values in my dataset and I'm unsure how to handle them. Should I leave them, remove the rows/columns, or fill in the gaps?\n",
    "\n",
    "Can you provide the pros and cons of each option and what factors I should consider about my data and goals to make the best decision?\n",
    "\r\n",
    "To illustrate the full approach, let’s just say that I’ve made the executive decision to remove missing values.\r\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f11d61-cbd8-4ba5-9cbf-9578c823655c",
   "metadata": {},
   "source": [
    ":::{warning} Show AI-Solution\n",
    ":class: dropdown\n",
    "**Handling Missing Data: Removing Missing Values**\n",
    "\n",
    "When dealing with missing data in a dataset, one common approach is to remove the rows or columns containing missing values. Here's a detailed look at the pros, cons, factors to consider, and an example workflow if you decide to remove missing values.\n",
    "\n",
    "**Pros of Removing Missing Values**\n",
    "\n",
    "- **Simplicity:** Removing missing values is straightforward and easy to implement.\n",
    "- **Preserves Data Integrity:** Avoids making assumptions or imputations that could potentially skew analysis.\n",
    "- **Compatibility:** Ensures compatibility with certain machine learning algorithms that do not handle missing data well.\n",
    "\n",
    "**Cons of Removing Missing Values**\n",
    "\n",
    "- **Loss of Data:** Reduces the size of the dataset, potentially leading to loss of valuable information.\n",
    "- **Bias:** If missing data are not randomly distributed, removing them could bias the analysis.\n",
    "- **Impact on Representativeness:** Removing too many rows could affect the representativeness of the dataset.\n",
    "\n",
    "**Factors to Consider**\n",
    "\n",
    "1. **Amount of Missing Data:**\n",
    "   Evaluate how much data would be lost by removing missing values. If a significant portion of your data is missing, consider alternative methods like imputation.\n",
    "\n",
    "2. **Data Distribution:**\n",
    "   Determine if missing values are randomly distributed or if there's a pattern. Removing them might bias your analysis if there's a systematic reason for missing data.\n",
    "\n",
    "3. **Impact on Results:**\n",
    "   Consider the potential impact on your analysis and the goals of your study. Removing missing values may be acceptable if it doesn't compromise the integrity of your findings.\n",
    "\n",
    "4. **Model Requirements:**\n",
    "   Check if your machine learning or statistical models require complete datasets or specific preprocessing steps.\n",
    "\n",
    "**Example Workflow**\n",
    "\n",
    "Here’s a simplified example of how you might proceed with removing missing values using Python and pandas:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Display initial count of missing values\n",
    "print(\"Initial count of missing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Remove rows with any missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Display count of missing values after removal\n",
    "print(\"Count of missing values after removal:\\n\", df_clean.isnull().sum())\n",
    "```\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "By deciding to remove missing values, you've opted for a straightforward approach to handling data gaps. It's essential to weigh the pros and cons carefully based on the specifics of your dataset, your analysis goals, and the requirements of the models you intend to use. \n",
    "\n",
    "- **Document Decisions:** Always document your decisions regarding handling missing data to ensure transparency and reproducibility.\n",
    "- **Consider Sensitivity Analyses:** Conduct sensitivity analyses to assess how robust your findings are to different handling strategies for missing data.\n",
    "\n",
    "This approach ensures that your dataset is cleaner and suitable for analysis, aligning with your specific analytical goals while maintaining data integrity.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74874012-0802-4d65-b574-523d10263368",
   "metadata": {},
   "source": [
    "Based on what you've read and seen, you should now have decided on how you want to approach the problem, which means it's time to implement your chosen solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58adcff3-5ed6-4c56-8288-e4053e366246",
   "metadata": {},
   "source": [
    "## 3. Implementing a solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a10e44e-cae6-4231-a547-63d6f64bd5a4",
   "metadata": {},
   "source": [
    ":::{note} **Use GenAI** to remove missing values in Python\n",
    "Having made your decision about how to solve the problem now, you can use GenAI again to generate some concise code to identify rows with missing values and remove them.\n",
    ":::{dropdown} Example Prompt\n",
    ":::{code-cell}\n",
    "Generate Python code that will identify missing values and remove any rows with missing values. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f00ec2-d1a9-47c3-a30a-d2c0b3ba6d29",
   "metadata": {},
   "source": [
    ":::{warning} Show AI-Solution\n",
    ":class: dropdown\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset (replace 'your_data.csv' with your actual dataset)\n",
    "df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Identify missing values\n",
    "print(\"Missing values before removal:\\n\", df.isnull().sum())\n",
    "\n",
    "# Remove rows with any missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "# Identify missing values after removal (should ideally show zeros)\n",
    "print(\"Missing values after removal:\\n\", df_clean.isnull().sum())\n",
    "\n",
    "# Optional: Display the cleaned DataFrame\n",
    "print(\"Cleaned DataFrame:\")\n",
    "print(df_clean.head())\n",
    "```\n",
    "\n",
    "\n",
    "In this code snippet:\n",
    "\n",
    "- Replace `'your_data.csv'` with the path or name of your actual dataset file.\n",
    "- `df.isnull().sum()` is used to check the number of missing values in each column before removing any rows.\n",
    "- `df.dropna()` removes all rows containing any missing values.\n",
    "- `df_clean.isnull().sum()` checks again for missing values in each column after removal to confirm that there are no missing values left.\n",
    "- The `print(df_clean.head())` line optionally displays the cleaned DataFrame to verify the results.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd9361d-666f-4a32-b018-4cc2237b4e86",
   "metadata": {},
   "source": [
    ":::{tip} AI-Sandbox\n",
    "Your turn to play around with the code and develop a solution to handle missing values in a DataFrame!\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45fcab7-17cf-4490-8640-665e77eccbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can enter your own AI-generated code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b141a945-bebe-4631-95cf-68cb6cb44f11",
   "metadata": {},
   "source": [
    "## 4. Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff4e5e-4054-4177-bd81-68b66390283a",
   "metadata": {},
   "source": [
    "Here is the DataFrame:\n",
    "\n",
    "If you fill the missing value with mean, you will get 31.5 as the age, while our column is of type `Integer`. You have to be careful with these kinds of issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d97501-d88e-43bf-a0e0-6a9c0aaa0681",
   "metadata": {},
   "source": [
    ":::{note} **Use GenAI** to troubleshoot data type issues\n",
    "\n",
    ":::{dropdown} Example Prompt\n",
    ":::{code-cell}\n",
    "How do I handle data-type issues when filling in the missing values in a DataFrame?\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f11b34-1964-4524-afe3-abc48b6f36aa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    ":::{warning} Show AI-Solution\n",
    ":class: dropdown\n",
    "\n",
    "1. **Identify Data-Type Mismatch:**\n",
    "   Before filling missing values, check the data types of each column using `df.dtypes`. Ensure numeric columns are correctly represented as `int64` or `float64` and not as `object` or other incompatible types.\n",
    "\n",
    "   ```python\n",
    "   import pandas as pd\n",
    "   \n",
    "   # Example DataFrame\n",
    "   data = {'A': [1, 2, None, 4, 5],\n",
    "           'B': ['6', '7', '8', None, '10']}\n",
    "   \n",
    "   df = pd.DataFrame(data)\n",
    "   \n",
    "   # Display initial data types\n",
    "   print(\"Initial data types:\")\n",
    "   print(df.dtypes)\n",
    "    ```\n",
    "\n",
    "2. **Convert Data Types if Necessary**\n",
    "\n",
    "    If numeric columns are stored as strings (`object`), convert them using `pd.to_numeric()` or `astype()` to ensure compatibility for numerical operations and imputation.\n",
    "\n",
    "```python\n",
    "    # Convert 'B' column from string to numeric (int or float)\n",
    "    df['B'] = pd.to_numeric(df['B'], errors='coerce')\n",
    "    \n",
    "    # Display data types after conversion\n",
    "    print(\"\\nData types after conversion:\")\n",
    "    print(df.dtypes)\n",
    "```\n",
    "\n",
    "3. **Handle Missing Values**\n",
    "\n",
    "Choose an appropriate strategy (mean, median, mode, interpolation, constant) to fill missing values (`NaN`) in numeric columns after ensuring consistent data types.\n",
    "\n",
    "```python\n",
    "# Fill missing values in 'A' column with mean\n",
    "mean_A = df['A'].mean()\n",
    "df['A'] = df['A'].fillna(mean_A)\n",
    "\n",
    "# Fill missing values in 'B' column with median (after conversion)\n",
    "median_B = df['B'].median()\n",
    "df['B'] = df['B'].fillna(median_B)\n",
    "\n",
    "# Display DataFrame after filling missing values\n",
    "print(\"\\nDataFrame after filling missing values:\")\n",
    "print(df)\n",
    "```\n",
    "\n",
    "4. **Validate Data Types After Imputation**\n",
    "\n",
    "After filling missing values, verify the data types of columns using `df.dtypes` to ensure consistency and compatibility with your analysis requirements.\n",
    "\n",
    "```python\n",
    "# Validate data types after filling missing values\n",
    "print(\"\\nData types after filling missing values:\")\n",
    "print(df.dtypes)\n",
    "```\n",
    "\n",
    "By following these steps in your data preprocessing pipeline, you can effectively handle data-type issues when filling missing values in a DataFrame, ensuring data integrity and compatibility for subsequent analysis or modeling tasks.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b192fc6-ae01-42a3-9614-13d3934617e9",
   "metadata": {},
   "source": [
    "# DIY Data Wrangling with GenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b82b93-a72a-431d-81f5-4b9f742c341f",
   "metadata": {},
   "source": [
    "Here are some tasks ranked from simple to advanced that you can tackle with GenAI solutions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe7e955-c983-4b97-a284-1f2ca88a0030",
   "metadata": {},
   "source": [
    ":::{tip} AI-Sandbox\n",
    "1. **Duplicates Removal**\n",
    "   - **Problem:** Identify and remove duplicate rows from a dataset.\n",
    "  \n",
    ":::{dropdown} Example Prompt\n",
    ":::{code-cell}\n",
    "I want to identify and remove duplicate rows from a dataset. \n",
    "\n",
    "How do I do that in Python with my dataset?\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfa8f85-fa74-4bda-b2df-85b6909cc5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can enter your own AI-generated code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9673047-8511-4399-b762-7081fdc4783b",
   "metadata": {},
   "source": [
    "2. **Creating New Columns**\n",
    "   - **Problem:** Combine existing columns (e.g., 'LATITUDE' and 'LONGITUDE') into a new column ('COORDINATES').\n",
    "   - **Prompt:** Help me in creating a new column named 'COORDINATES' by combining the 'LATITUDE' and 'LONGITUDE' columns as strings. Provide a solution using string manipulation functions to concatenate values from multiple columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a3b912-0259-48d1-a7fd-b025f81f9a46",
   "metadata": {},
   "source": [
    "3. **Merging CSVs**\n",
    "   - **Problem:** Combine multiple CSV files located in a directory ('../Datasets/NOAA_Weather') into a single dataset.\n",
    "   - **Prompt:** How can I merge multiple CSV files located in a directory into a single dataset? Utilize file handling and data integration techniques to seamlessly combine separate datasets for comprehensive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d1bfc9-5cc1-4f26-9cdc-132b1a80efa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e899c4d-c3c8-4ece-94c9-31fe0c9f207c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
